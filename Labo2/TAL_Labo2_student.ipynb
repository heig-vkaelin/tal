{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c7/HEIG-VD_Logo_96x29_RVB_ROUGE.png\" alt=\"HEIG-VD Logo\" width=\"250\" /> \n",
    "\n",
    "# Cours TAL - Laboratoire 2\n",
    "# Mise en œuvre et évaluation de *POS taggers* pour le français\n",
    "\n",
    "**Objectif**\n",
    "\n",
    "Appliquer des étiqueteurs morphosyntaxiques (POS taggers) disponibles dans NLTK et dans les outils Stanford NLP à des textes français, puis quantifier leurs performances.\n",
    "\n",
    "**Instructions initiales**\n",
    "\n",
    "* Télécharger l'archive `UD_French-GSD-withBlankLines.zip` fournie sur Cyberlearn.\n",
    "* Placer les trois fichiers qu'elle contient dans le même dossier que le notebook.\n",
    "* Ce sont des textes en français annotés avec les POS tags, provenant du projet ([Universal Dependencies](https://github.com/UniversalDependencies/UD_French-GSD)), et légèrement modifiés.\n",
    "  - le fichier `fr-ud-train.conllu3` est destiné à l'entraînement\n",
    "  - le fichier `fr-ud-dev.conllu3` est destiné aux tests préliminaires et aux réglages des paramètres\n",
    "  - le fichier `fr-ud-test.conllu3` est destiné à l'évaluation finale.\n",
    "\n",
    "**Questions préliminaires**\n",
    "\n",
    "* En inspectant les fichiers, veuillez indiquer le numéro de la colonne où se trouvent les mots, et celui de la colonne où se trouvent leur étiquettes morpho-syntaxiques (*POS tags*).\n",
    "* Veuillez chercher sur le Web la liste des *POS tags* du projet Universal Dependencies, avec leurs définitions, et indiquer l'URL ci-dessous.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Si la première colonne est la colonne numéro 1)\n",
    "\n",
    "Colonne des mots: 2\n",
    "\n",
    "Colonne des POS tags: 4\n",
    "\n",
    "Lien des POS tags du projet Universal Dependencies: https://universaldependencies.org/u/pos/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Veuillez déterminer et afficher le nombre de tokens de chacun des trois fichiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tokens dans le fichier fr-ud-dev.conllu3: 36830\n",
      "Nombre de tokens dans le fichier fr-ud-train.conllu3: 366371\n",
      "Nombre de tokens dans le fichier fr-ud-test.conllu3: 10298\n"
     ]
    }
   ],
   "source": [
    "file_dev = \"fr-ud-dev.conllu3\"\n",
    "file_train = \"fr-ud-train.conllu3\"\n",
    "file_test = \"fr-ud-test.conllu3\"\n",
    "\n",
    "files = [file_dev, file_train, file_test]\n",
    "\n",
    "for file in files:\n",
    "    with open(file, \"r\") as f:\n",
    "        # On compte le nombre de lignes dans le fichier sans compter les lignes vides\n",
    "        nb_lines = len([line for line in f if line.strip() != \"\"])\n",
    "        print(\"Nombre de tokens dans le fichier {}: {}\".format(file, nb_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1 : Évaluer le Stanford POS tagger avec les modèles fournis pour le français\n",
    "\n",
    "L'Université de Stanford fournit un étiqueteur morpho-syntaxique (POS tagger) qui utilise l'apprentissage automatique (https://nlp.stanford.edu/software/tagger.html) appelé Maxent Tagger.  Le tagger et ses modèles multilingues peuvent être téléchargés à l'URL ci-dessus (archive ZIP suivant le lien *Download > full Stanford Tagger version 3.9.2*, 130 MB environ).  \n",
    "\n",
    "Pour simplifier, on vous propose de télécharger séparément le programme Java [stanford-postagger.jar](https://drive.switch.ch/index.php/s/hMY6yO7lmoQJuS3) et le modèle français [french-ud.tagger](https://drive.switch.ch/index.php/s/4HSqKRTTTkCgPfB) fournis par l'enseignant (mot de passe = reference).  Enregistrez ces deux fichiers dans le même dossier que ce notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le Maxent Tagger est en Java, et peut être exécuté depuis ce notebook avec un appel Java en ligne de commande.  Pour exécuter une commande système depuis le notebook, ajouter '!' devant (par exemple `! dir` ou `! ls`).  Utilisez la [documentation du Maxent Tagger](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/tagger/maxent/MaxentTagger.html), et plus précisément la section *Tagging and Testing from the command line*, pour comprendre comment l'invoquer.  Java doit être installé sur votre système, et si nécessaire, exécuter :\n",
    "```python\n",
    "import os\n",
    "java_path = 'C:/Program Files (x86)/Java/jdk1.8.0_20/bin/java.exe'  # votre chemin de java.exe\n",
    "os.environ['JAVA_HOME'] = java_path   # attention aux slash (pas backslash sous Windows)\n",
    "```\n",
    "*Note* : il est également possible d'appeler ce tagger avec des commandes NLTK grâce au module [nltk.tag.stanford](https://www.nltk.org/_modules/nltk/tag/stanford.html) mais la gestion des *paths* entre Java, les classes et les modèles peut être compliquée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "\n",
    "stanford_dir = './'\n",
    "modelfile = stanford_dir + 'french-ud.tagger'\n",
    "jarfile = stanford_dir + 'stanford-postagger.jar'\n",
    "\n",
    "st = StanfordPOSTagger(model_filename=modelfile,\n",
    "                       path_to_jar=jarfile, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "Appliquez le Maxent Tagger pour étiqueter le fichier `fr-ud-dev.conllu3` et demandez à Maxent Tagger de mesurer la qualité par comparaison à une l'annotation de référence fournie dans le fichier. Quels sont les scores obtenus ?  Quel est le nombre le plus important?  Indiquez ces réponses en commentaires du code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default properties from tagger french-ud.tagger\n",
      "Loading POS tagger from french-ud.tagger ... done [0.1 sec].\n",
      "Tagged 36830 words at 46327,04 words per second.\n",
      "Model french-ud.tagger has xSize=304855, ySize=18, and numFeatures=104853.\n",
      "Results on 1478 sentences and 36830 words, of which 3049 were unknown.\n",
      "Total sentences right: 144 (9,742896%); wrong: 1334 (90,257104%).\n",
      "Total tags right: 32360 (87,863155%); wrong: 4470 (12,136845%).\n",
      "Unknown words right: 2232 (73,204329%); wrong: 817 (26,795671%).\n"
     ]
    }
   ],
   "source": [
    "!java -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger -model 'french-ud.tagger' -testFile 'format=TSV,wordColumn=1,tagColumn=3,fr-ud-dev.conllu3' -verboseResults false\n",
    "\n",
    "# Phrases: 1478\n",
    "#   Correctes:  144  (9.742896%)\n",
    "#   Fausses:    1334 (90.257104%)\n",
    "\n",
    "# Tags: 36830\n",
    "#   Corrects:   32360 (87.863155%)\n",
    "#   Faux:       4470  (12.136845%)\n",
    "\n",
    "# Mots inconnus: 3049\n",
    "#   Corrects:   2232 (73.204329%)\n",
    "#   Faux:       817  (26.795671%)\n",
    "\n",
    " \n",
    "# Le nombre le plus important est le nombre de tags.\n",
    "\n",
    "# Nous observons que le tagger s'en sort bien avec les tags et mêmes les mots inconnus mais qu'il a plus de mal avec les phrases. Ceci s'explique assez facilement car une phrase est considérée comme fausse si au moins un mot est mal taggé. Ce qui est le cas pour la plupart des phrases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De même, appliquez le Maxent Tagger pour étiqueter le fichier `fr-ud-test.conllu3` et indiquez la précision du tagger en commentaires du code (#)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default properties from tagger french-ud.tagger\n",
      "Loading POS tagger from french-ud.tagger ... done [0.1 sec].\n",
      "Tagged 10298 words at 37860,29 words per second.\n",
      "Model french-ud.tagger has xSize=304855, ySize=18, and numFeatures=104853.\n",
      "Results on 416 sentences and 10298 words, of which 697 were unknown.\n",
      "Total sentences right: 54 (12,980769%); wrong: 362 (87,019231%).\n",
      "Total tags right: 8960 (87,007186%); wrong: 1338 (12,992814%).\n",
      "Unknown words right: 487 (69,870875%); wrong: 210 (30,129125%).\n"
     ]
    }
   ],
   "source": [
    "!java -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger -model 'french-ud.tagger' -testFile 'format=TSV,wordColumn=1,tagColumn=3,fr-ud-test.conllu3' -verboseResults false\n",
    "\n",
    "# Précision du tagger:\n",
    "#\n",
    "#   Phrases: ~12.98%\n",
    "#   Tokens: ~87.01%\n",
    "#   Mots inconnus: ~69.87%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question subsidiare** : combien de phrases et de mots le tagger trouve-t-il dans les fichiers `fr-ud-dev.conllu3` et `fr-ud-test.conllu3` ?  Comparez avec votre propre estimation du nombre de mots."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour le fichier de dev:\n",
    "\n",
    "Le tagger trouve 36830 mots et 1478 phrases. \n",
    "\n",
    "Nous avions estimé 36830 mots ce qui est exact. \n",
    "\n",
    "### Pour le fichier de test:\n",
    "\n",
    "Le tagger trouve 10298 mots et 416 phrases. \n",
    "\n",
    "Nous avions estimé 10298 mots ce qui est exact. \n",
    "\n",
    "Nous avions donc bien estimé le nombre de mots dans les fichiers en comptant le nombre de lignes non vides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2 : Entraîner le Stanford POS tagger pour obtenir de nouveaux modèles\n",
    "\n",
    "Le but de cette partie est d'entraîner le Maxent Tagger sur les données UD en français (`fr-ud-train.conllu3`), puis de comparer le modèle obtenu avec les modèles fournis par Stanford pour le français, testés dans la partie 1A.  \n",
    "\n",
    "Suivre la [documentation de Maxent Tagger](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/tagger/maxent/MaxentTagger.html) pour l'entraîner sur le fichier `fr-ud-train.conllu3` et le tester sur `fr-ud-test.conllu3`.  Regardez la section *Training from the command line*. \n",
    "\n",
    "La configuration du système pour effectuer l'entraînement est donnée dans un fichier texte, qui peut être produit en suivant la documentation (option `-genprops` pour obtenir un template qui sera édité), soit en s'inspirant du fichier [french-ud.tagger.props](https://drive.switch.ch/index.php/s/gHlam9S74HG2Q4X) accompagnant le modèle `french-ud.tagger` que vous avez utilisé ci-dessus.  Pensez à donner un nouveau nom à votre fichier modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "\n",
    "* Créez un fichier `myFrench-ud.tagger.props` qui aboutit à un bon entraînement.  Vous pourrez expérimenter plusieurs fois et proposer le meilleur fichier.  Citez dans le notebook les paramètres sur lesquels vous avez agi.\n",
    "\n",
    "* Lancez l'entraînement sur le fichier `fr-ud-train.conllu3` (s'il ne tient pas en mémoire, utilisez seulement `fr-ud-dev.conllu3`). Pendant l’entraînement (> 10 minutes, 500 itérations), regardez la suite du travail.\n",
    "\n",
    "* Évaluez votre modèle comme ci-dessus (sur `dev` et sur `test`).  Quel modèle est meilleur, le vôtre ou celui fourni par Stanford ?  Formulez une hypothèse expliquant ce résultat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un fichier de propriétés pour le tagger vierge (finalement non utilisé)\n",
    "# !java -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger \\\n",
    "#   -genprops > myFrench-ud.tagger.props"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons modifié les paramètres suivantes dans le fichier `myFrench-ud.tagger.props`:\n",
    "* `iterations` : 500 au lieu de 100\n",
    "* `rareWordMinFeatureThresh` : 3 au lieu de 10 (Discard les rareswords qui apparaisent moins de 3 fois)\n",
    "* `rareWordThresh` : 10 au lieu de 5 (Condidère qu'un mot est rare s'il apparait moins de 10 fois)\n",
    "\n",
    "Nous avons donc augmenté légèrement le nombre de mots qui seront considérés comme rares mais nous avons réduit le minimum de fois qu'un mot doit apparaître pour être discard. Cela permet de garder environ le même nombre de mots dans le modèle. Nous avons également augmenté le nombre d'itérations pour que le modèle soit plus précis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## tagger training invoked at Mon Mar 13 10:52:58 CET 2023 with arguments:\n",
      "                   model = myFrench-ud.tagger\n",
      "                    arch = left3words,naacl2003unknowns,unicodeshapes(-1,1)\n",
      "            wordFunction = \n",
      "               trainFile = format=TSV,wordColumn=1,tagColumn=3,fr-ud-dev.conllu3\n",
      "         closedClassTags = \n",
      " closedClassTagThreshold = 40\n",
      " curWordMinFeatureThresh = 2\n",
      "                   debug = false\n",
      "             debugPrefix = \n",
      "            tagSeparator = _\n",
      "                encoding = utf-8\n",
      "              iterations = 500\n",
      "                    lang = french\n",
      "    learnClosedClassTags = false\n",
      "        minFeatureThresh = 2\n",
      "           openClassTags = \n",
      "rareWordMinFeatureThresh = 3\n",
      "          rareWordThresh = 7\n",
      "                  search = qn\n",
      "                    sgml = false\n",
      "            sigmaSquared = 0.0\n",
      "                   regL1 = 0.75\n",
      "               tagInside = \n",
      "                tokenize = true\n",
      "        tokenizerFactory = \n",
      "        tokenizerOptions = asciiQuotes\n",
      "                 verbose = false\n",
      "          verboseResults = false\n",
      "    veryCommonWordThresh = 250\n",
      "                xmlInput = null\n",
      "              outputFile = \n",
      "            outputFormat = slashTags\n",
      "     outputFormatOptions = \n",
      "                nthreads = 1\n",
      "TaggerExperiments: adding word/tags\n",
      "Loading tagged words from fr-ud-dev.conllu3\n",
      "Read 36830 words from fr-ud-dev.conllu3 [done].\n",
      "Read 1478 sentences, min 3 words, max 122 words.\n",
      "Featurizing tagged data tokens...\n",
      "Featurized 38308 data tokens [done].\n",
      "xSize [num Phi templates] = 34166; ySize [num classes] = 19\n",
      "Hashing histories ...\n",
      "Hashed 34166 histories.\n",
      "Hashing populated histories ...\n",
      "Hashed populated histories.\n",
      "TaggerExperiments.getFeaturesNew: initializing fnumArr.\n",
      "  length of sTemplates keys: 107126\n",
      "getFeaturesNew adding features ...\n",
      "  total feats: 107126, populated: 28553\n",
      "  Max features per x,y pair: 33\n",
      "  Max non-zero y values for an x: 19\n",
      "  Number of non-zero feature x,y pairs: 588368\n",
      "  Number of zero feature x,y pairs: 60786\n",
      "end getFeaturesNew.\n",
      "Samples from format=TSV,wordColumn=1,tagColumn=3,fr-ud-dev.conllu3\n",
      "Number of features: 28553\n",
      "Tag set: [CCONJ, PRON, AUX, PROPN, SYM, NUM, ADJ, SCONJ, ADP, DET, ADV, PUNCT, .$$., PART, VERB, X, INTJ, NOUN, _]\n",
      " pcond initialized \n",
      " zlambda initialized \n",
      " ftildeArr initialized \n",
      "QNMinimizer called on double function of 28553 variables, using M = 10.\n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 0: neg. log cond. likelihood = 112795.56841383954 [1 calls to valueAt]\n",
      "               An explanation of the output:\n",
      "Iter           The number of iterations\n",
      "evals          The number of function evaluations\n",
      "SCALING        <D> Diagonal scaling was used; <I> Scaled Identity\n",
      "LINESEARCH     [## M steplength]  Minpack linesearch\n",
      "                   1-Function value was too high\n",
      "                   2-Value ok, gradient positive, positive curvature\n",
      "                   3-Value ok, gradient negative, positive curvature\n",
      "                   4-Value ok, gradient negative, negative curvature\n",
      "               [.. B]  Backtracking\n",
      "VALUE          The current function value\n",
      "TIME           Total elapsed time\n",
      "|GNORM|        The current norm of the gradient\n",
      "{RELNORM}      The ratio of the current to initial gradient norms\n",
      "AVEIMPROVE     The average improvement / current value\n",
      "EVALSCORE      The last available eval score\n",
      " \n",
      "Iter ## evals ## <SCALING> [LINESEARCH] VALUE TIME |GNORM| {RELNORM} AVEIMPROVE EVALSCORE\n",
      "\n",
      "lambda 2505 too big: 405.19473684198806\n",
      "lambda 3196 too big: 229.52631578943547\n",
      "lambda 5424 too big: 290.7157894735265\n",
      "lambda 6124 too big: 234.93684210520138\n",
      "lambda 9144 too big: 375.02105263142386\n",
      "lambda 12193 too big: 218.89473684205473\n",
      "lambda 12457 too big: 338.42105263139536\n",
      "lambda 12461 too big: 230.06842105250664\n",
      "lambda 18522 too big: 271.6368421051723\n",
      "lambda 19623 too big: 290.7157894735265\n",
      "lambda 20307 too big: 222.8263157894192\n",
      "lambda 26703 too big: 230.06842105250664\n",
      "lambda 26710 too big: 338.42105263139536\n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 1: neg. log cond. likelihood = 102311.76673608257 [4 calls to valueAt]\n",
      "Iter 1 evals 1 <D> [11M 4,572E-5] 1,023E5 0,32s |1,318E4| {8,363E-1} 0,000E0 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 2: neg. log cond. likelihood = 60058.37268274752 [5 calls to valueAt]\n",
      "Iter 2 evals 4 <D> [M 1,000E0] 6,006E4 0,48s |7,073E3| {4,488E-1} 3,518E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 3: neg. log cond. likelihood = 49072.19337087577 [6 calls to valueAt]\n",
      "Iter 3 evals 5 <D> [M 1,000E0] 4,907E4 0,62s |5,452E3| {3,459E-1} 3,616E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 4: neg. log cond. likelihood = 44082.43805130536 [7 calls to valueAt]\n",
      "Iter 4 evals 6 <D> [M 1,000E0] 4,408E4 0,75s |6,072E3| {3,853E-1} 3,302E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 5: neg. log cond. likelihood = 37258.800433580946 [8 calls to valueAt]\n",
      "Iter 5 evals 7 <D> [M 1,000E0] 3,726E4 0,88s |2,934E3| {1,862E-1} 3,492E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 6: neg. log cond. likelihood = 33226.890929485424 [9 calls to valueAt]\n",
      "Iter 6 evals 8 <D> [M 1,000E0] 3,323E4 1,01s |2,481E3| {1,574E-1} 3,465E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 7: neg. log cond. likelihood = 27961.41129774144 [10 calls to valueAt]\n",
      "Iter 7 evals 9 <D> [M 1,000E0] 2,796E4 1,14s |4,181E3| {2,653E-1} 3,799E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 8: neg. log cond. likelihood = 25483.704825890265 [12 calls to valueAt]\n",
      "Iter 8 evals 10 <D> [1M 4,441E-1] 2,548E4 1,38s |1,993E3| {1,265E-1} 3,768E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 9: neg. log cond. likelihood = 24069.207321282698 [13 calls to valueAt]\n",
      "Iter 9 evals 12 <D> [M 1,000E0] 2,407E4 1,51s |1,268E3| {8,045E-2} 3,612E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 10: neg. log cond. likelihood = 21422.685733506372 [14 calls to valueAt]\n",
      "Iter 10 evals 13 <D> [M 1,000E0] 2,142E4 1,64s |2,047E3| {1,299E-1} 3,776E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 11: neg. log cond. likelihood = 19197.007790375625 [15 calls to valueAt]\n",
      "Iter 11 evals 14 <D> [M 1,000E0] 1,920E4 1,77s |1,711E3| {1,086E-1} 2,129E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 12: neg. log cond. likelihood = 17212.230536711526 [16 calls to valueAt]\n",
      "Iter 12 evals 15 <D> [M 1,000E0] 1,721E4 1,90s |1,247E3| {7,911E-2} 1,851E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 13: neg. log cond. likelihood = 14889.632219124434 [17 calls to valueAt]\n",
      "Iter 13 evals 16 <D> [M 1,000E0] 1,489E4 2,03s |1,092E3| {6,928E-2} 1,961E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 14: neg. log cond. likelihood = 13119.011813732222 [18 calls to valueAt]\n",
      "Iter 14 evals 17 <D> [M 1,000E0] 1,312E4 2,16s |6,885E2| {4,369E-2} 1,840E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 15: neg. log cond. likelihood = 12115.944191033777 [19 calls to valueAt]\n",
      "Iter 15 evals 18 <D> [M 1,000E0] 1,212E4 2,29s |1,931E3| {1,225E-1} 1,742E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 16: neg. log cond. likelihood = 10968.056199401495 [21 calls to valueAt]\n",
      "Iter 16 evals 19 <D> [1M 4,539E-1] 1,097E4 2,54s |9,359E2| {5,938E-2} 1,549E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 17: neg. log cond. likelihood = 10338.444063444873 [22 calls to valueAt]\n",
      "Iter 17 evals 21 <D> [M 1,000E0] 1,034E4 2,67s |6,310E2| {4,004E-2} 1,465E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 18: neg. log cond. likelihood = 9755.917358692826 [23 calls to valueAt]\n",
      "Iter 18 evals 22 <D> [M 1,000E0] 9,756E3 2,80s |5,260E2| {3,337E-2} 1,467E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 19: neg. log cond. likelihood = 8633.45622975602 [24 calls to valueAt]\n",
      "Iter 19 evals 23 <D> [M 1,000E0] 8,633E3 2,93s |8,412E2| {5,338E-2} 1,481E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 20: neg. log cond. likelihood = 8600.378454710139 [25 calls to valueAt]\n",
      "Iter 20 evals 24 <D> [M 1,000E0] 8,600E3 3,06s |1,722E3| {1,092E-1} 1,232E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 21: neg. log cond. likelihood = 7528.8740688791795 [26 calls to valueAt]\n",
      "Iter 21 evals 25 <D> [M 1,000E0] 7,529E3 3,19s |6,048E2| {3,838E-2} 1,286E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 22: neg. log cond. likelihood = 7050.449174264442 [27 calls to valueAt]\n",
      "Iter 22 evals 26 <D> [M 1,000E0] 7,050E3 3,32s |3,588E2| {2,277E-2} 1,112E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 23: neg. log cond. likelihood = 6720.050405595365 [29 calls to valueAt]\n",
      "Iter 23 evals 27 <D> [1M 4,629E-1] 6,720E3 3,57s |1,135E3| {7,201E-2} 9,522E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 24: neg. log cond. likelihood = 6107.804589332649 [30 calls to valueAt]\n",
      "Iter 24 evals 29 <D> [M 1,000E0] 6,108E3 3,70s |5,765E2| {3,658E-2} 9,837E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 25: neg. log cond. likelihood = 5710.077613222339 [31 calls to valueAt]\n",
      "Iter 25 evals 30 <D> [M 1,000E0] 5,710E3 3,83s |3,426E2| {2,174E-2} 9,208E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 26: neg. log cond. likelihood = 5345.346799240618 [32 calls to valueAt]\n",
      "Iter 26 evals 31 <D> [M 1,000E0] 5,345E3 3,96s |3,626E2| {2,301E-2} 9,341E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 27: neg. log cond. likelihood = 4982.055252843906 [33 calls to valueAt]\n",
      "Iter 27 evals 32 <D> [M 1,000E0] 4,982E3 4,09s |1,148E3| {7,285E-2} 9,582E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 28: neg. log cond. likelihood = 4524.402861918487 [35 calls to valueAt]\n",
      "Iter 28 evals 33 <D> [1M 4,838E-1] 4,524E3 4,34s |4,764E2| {3,023E-2} 9,082E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 29: neg. log cond. likelihood = 4264.791835069988 [36 calls to valueAt]\n",
      "Iter 29 evals 35 <D> [M 1,000E0] 4,265E3 4,47s |3,151E2| {1,999E-2} 1,017E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 30: neg. log cond. likelihood = 4021.2184372887446 [37 calls to valueAt]\n",
      "Checking model correctness; x size 34166 , ysize 19\n",
      "Constraint 12782 not satisfied emp 0,0542 exp 0,0532 diff 0,001 lambda -0,0046\n",
      "Constraint 27061 not satisfied emp 0,0542 exp 0,0532 diff 0,001 lambda -0,0046\n",
      "Iter 30 evals 36 <D> [M 1,000E0] 4,021E3 4,60s |2,684E2| {1,703E-2} 8,723E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 31: neg. log cond. likelihood = 3695.468017590032 [38 calls to valueAt]\n",
      "Iter 31 evals 37 <D> [M 1,000E0] 3,695E3 4,76s |6,331E2| {4,017E-2} 9,079E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 32: neg. log cond. likelihood = 3425.2745238597954 [39 calls to valueAt]\n",
      "Iter 32 evals 38 <D> [M 1,000E0] 3,425E3 4,89s |4,120E2| {2,614E-2} 9,619E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 33: neg. log cond. likelihood = 3282.9980470027745 [40 calls to valueAt]\n",
      "Iter 33 evals 39 <D> [M 1,000E0] 3,283E3 5,02s |4,183E2| {2,654E-2} 8,604E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 34: neg. log cond. likelihood = 3062.855865942423 [41 calls to valueAt]\n",
      "Iter 34 evals 40 <D> [M 1,000E0] 3,063E3 5,15s |1,637E2| {1,039E-2} 8,643E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 35: neg. log cond. likelihood = 2859.000928333874 [42 calls to valueAt]\n",
      "Iter 35 evals 41 <D> [M 1,000E0] 2,859E3 5,28s |5,208E2| {3,305E-2} 8,697E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 36: neg. log cond. likelihood = 2668.069262683966 [44 calls to valueAt]\n",
      "Iter 36 evals 42 <D> [1M 4,190E-1] 2,668E3 5,53s |3,565E2| {2,262E-2} 8,673E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 37: neg. log cond. likelihood = 2555.2622505046297 [45 calls to valueAt]\n",
      "Iter 37 evals 44 <D> [M 1,000E0] 2,555E3 5,66s |2,109E2| {1,338E-2} 7,706E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 38: neg. log cond. likelihood = 2325.6090883003403 [46 calls to valueAt]\n",
      "Iter 38 evals 45 <D> [M 1,000E0] 2,326E3 5,78s |1,376E2| {8,733E-3} 8,338E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 39: neg. log cond. likelihood = 2214.7681041835244 [47 calls to valueAt]\n",
      "Iter 39 evals 46 <D> [M 1,000E0] 2,215E3 5,91s |4,520E2| {2,868E-2} 8,156E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 40: neg. log cond. likelihood = 2094.519415745385 [48 calls to valueAt]\n",
      "Iter 40 evals 47 <D> [M 1,000E0] 2,095E3 6,04s |3,773E2| {2,394E-2} 7,644E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 41: neg. log cond. likelihood = 1905.5102872529424 [49 calls to valueAt]\n",
      "Iter 41 evals 48 <D> [M 1,000E0] 1,906E3 6,17s |1,403E2| {8,902E-3} 7,976E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 42: neg. log cond. likelihood = 1795.4024998006646 [50 calls to valueAt]\n",
      "Iter 42 evals 49 <D> [M 1,000E0] 1,795E3 6,29s |9,777E1| {6,204E-3} 8,286E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 43: neg. log cond. likelihood = 1628.3081969149696 [51 calls to valueAt]\n",
      "Iter 43 evals 50 <D> [M 1,000E0] 1,628E3 6,42s |1,723E2| {1,093E-2} 8,810E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 44: neg. log cond. likelihood = 1536.0987674776916 [52 calls to valueAt]\n",
      "Iter 44 evals 51 <D> [M 1,000E0] 1,536E3 6,55s |2,421E2| {1,536E-2} 8,612E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 45: neg. log cond. likelihood = 1419.8930615225706 [53 calls to valueAt]\n",
      "Iter 45 evals 52 <D> [M 1,000E0] 1,420E3 6,67s |2,186E2| {1,387E-2} 8,791E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 46: neg. log cond. likelihood = 1333.151158816222 [54 calls to valueAt]\n",
      "Iter 46 evals 53 <D> [M 1,000E0] 1,333E3 6,79s |1,325E2| {8,411E-3} 9,167E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 47: neg. log cond. likelihood = 1303.5197275538635 [56 calls to valueAt]\n",
      "Iter 47 evals 54 <D> [1M 2,776E-1] 1,304E3 7,03s |1,397E2| {8,864E-3} 7,841E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 48: neg. log cond. likelihood = 1247.5789863016205 [57 calls to valueAt]\n",
      "Iter 48 evals 56 <D> [M 1,000E0] 1,248E3 7,16s |9,269E1| {5,882E-3} 7,753E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 49: neg. log cond. likelihood = 1153.7574638838723 [58 calls to valueAt]\n",
      "Iter 49 evals 57 <D> [M 1,000E0] 1,154E3 7,28s |9,322E1| {5,915E-3} 8,154E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 50: neg. log cond. likelihood = 1049.7021405300493 [59 calls to valueAt]\n",
      "Iter 50 evals 58 <D> [M 1,000E0] 1,050E3 7,40s |7,922E1| {5,027E-3} 8,153E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 51: neg. log cond. likelihood = 997.4807452648054 [61 calls to valueAt]\n",
      "Iter 51 evals 59 <D> [1M 4,436E-1] 9,975E2 7,63s |2,069E2| {1,313E-2} 7,999E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 52: neg. log cond. likelihood = 891.1938537595815 [62 calls to valueAt]\n",
      "Iter 52 evals 61 <D> [M 1,000E0] 8,912E2 7,74s |8,156E1| {5,175E-3} 8,271E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 53: neg. log cond. likelihood = 844.2789489472741 [63 calls to valueAt]\n",
      "Iter 53 evals 62 <D> [M 1,000E0] 8,443E2 7,86s |7,421E1| {4,709E-3} 8,194E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 54: neg. log cond. likelihood = 781.2515609404772 [64 calls to valueAt]\n",
      "Iter 54 evals 63 <D> [M 1,000E0] 7,813E2 7,97s |4,635E1| {2,941E-3} 8,175E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 55: neg. log cond. likelihood = 708.2694611379443 [65 calls to valueAt]\n",
      "Iter 55 evals 64 <D> [M 1,000E0] 7,083E2 8,09s |6,160E1| {3,908E-3} 8,823E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 56: neg. log cond. likelihood = 652.5499226713448 [66 calls to valueAt]\n",
      "Iter 56 evals 65 <D> [M 1,000E0] 6,525E2 8,20s |4,818E1| {3,057E-3} 9,976E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 57: neg. log cond. likelihood = 625.1610871309974 [67 calls to valueAt]\n",
      "Iter 57 evals 66 <D> [M 1,000E0] 6,252E2 8,31s |1,265E2| {8,025E-3} 9,956E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 58: neg. log cond. likelihood = 610.6333378679403 [68 calls to valueAt]\n",
      "Iter 58 evals 67 <D> [M 1,000E0] 6,106E2 8,42s |2,273E2| {1,442E-2} 8,894E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 59: neg. log cond. likelihood = 572.0394084253045 [70 calls to valueAt]\n",
      "Iter 59 evals 68 <D> [1M 4,694E-1] 5,720E2 8,62s |9,609E1| {6,097E-3} 8,350E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 60: neg. log cond. likelihood = 544.5375615772515 [71 calls to valueAt]\n",
      "Checking model correctness; x size 34166 , ysize 19\n",
      "Iter 60 evals 70 <D> [M 1,000E0] 5,445E2 8,72s |2,423E1| {1,537E-3} 8,318E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 61: neg. log cond. likelihood = 533.0271873543967 [72 calls to valueAt]\n",
      "Iter 61 evals 71 <D> [M 1,000E0] 5,330E2 8,85s |2,375E1| {1,507E-3} 6,719E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 62: neg. log cond. likelihood = 489.5225131865979 [73 calls to valueAt]\n",
      "Iter 62 evals 72 <D> [M 1,000E0] 4,895E2 8,95s |3,411E1| {2,165E-3} 7,247E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 63: neg. log cond. likelihood = 473.13662765675457 [75 calls to valueAt]\n",
      "Iter 63 evals 73 <D> [1M 4,524E-1] 4,731E2 9,15s |6,174E1| {3,918E-3} 6,512E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 64: neg. log cond. likelihood = 442.843346477264 [76 calls to valueAt]\n",
      "Iter 64 evals 75 <D> [M 1,000E0] 4,428E2 9,25s |2,839E1| {1,801E-3} 5,994E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 65: neg. log cond. likelihood = 417.80302522768244 [77 calls to valueAt]\n",
      "Iter 65 evals 76 <D> [M 1,000E0] 4,178E2 9,35s |2,029E1| {1,287E-3} 5,619E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 66: neg. log cond. likelihood = 391.2609286093271 [78 calls to valueAt]\n",
      "Iter 66 evals 77 <D> [M 1,000E0] 3,913E2 9,45s |3,194E1| {2,027E-3} 5,978E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 67: neg. log cond. likelihood = 371.32353215162374 [79 calls to valueAt]\n",
      "Iter 67 evals 78 <D> [M 1,000E0] 3,713E2 9,55s |3,218E1| {2,042E-3} 6,445E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 68: neg. log cond. likelihood = 357.81308863806447 [80 calls to valueAt]\n",
      "Iter 68 evals 79 <D> [M 1,000E0] 3,578E2 9,65s |3,963E1| {2,515E-3} 5,987E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 69: neg. log cond. likelihood = 351.9820545531625 [81 calls to valueAt]\n",
      "Iter 69 evals 80 <D> [M 1,000E0] 3,520E2 9,74s |6,894E1| {4,374E-3} 5,471E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 70: neg. log cond. likelihood = 347.665296878393 [82 calls to valueAt]\n",
      "Iter 70 evals 81 <D> [M 1,000E0] 3,477E2 9,84s |7,897E1| {5,011E-3} 5,332E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 71: neg. log cond. likelihood = 333.39006993114236 [83 calls to valueAt]\n",
      "Iter 71 evals 82 <D> [M 1,000E0] 3,334E2 9,93s |2,363E1| {1,499E-3} 4,683E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 72: neg. log cond. likelihood = 327.39028175535276 [84 calls to valueAt]\n",
      "Iter 72 evals 83 <D> [M 1,000E0] 3,274E2 10,03s |9,480E0| {6,015E-4} 4,452E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 73: neg. log cond. likelihood = 313.761136398392 [85 calls to valueAt]\n",
      "Iter 73 evals 84 <D> [M 1,000E0] 3,138E2 10,12s |1,982E1| {1,257E-3} 4,114E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 74: neg. log cond. likelihood = 303.60073929491665 [86 calls to valueAt]\n",
      "Iter 74 evals 85 <D> [M 1,000E0] 3,036E2 10,22s |2,347E1| {1,489E-3} 3,762E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 75: neg. log cond. likelihood = 292.73465485387874 [87 calls to valueAt]\n",
      "Iter 75 evals 86 <D> [M 1,000E0] 2,927E2 10,31s |3,131E1| {1,987E-3} 3,366E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 76: neg. log cond. likelihood = 281.7731621427781 [88 calls to valueAt]\n",
      "Iter 76 evals 87 <D> [M 1,000E0] 2,818E2 10,40s |1,227E1| {7,789E-4} 3,178E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 77: neg. log cond. likelihood = 273.7684215911635 [89 calls to valueAt]\n",
      "Iter 77 evals 88 <D> [M 1,000E0] 2,738E2 10,49s |1,861E1| {1,181E-3} 3,070E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 78: neg. log cond. likelihood = 265.10654634428096 [90 calls to valueAt]\n",
      "Iter 78 evals 89 <D> [M 1,000E0] 2,651E2 10,58s |1,244E1| {7,894E-4} 3,277E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 79: neg. log cond. likelihood = 259.6190142300424 [91 calls to valueAt]\n",
      "Iter 79 evals 90 <D> [M 1,000E0] 2,596E2 10,67s |2,106E1| {1,336E-3} 3,391E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 80: neg. log cond. likelihood = 250.04515744870966 [92 calls to valueAt]\n",
      "Iter 80 evals 91 <D> [M 1,000E0] 2,500E2 10,76s |1,306E1| {8,286E-4} 3,333E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 81: neg. log cond. likelihood = 246.64972723056349 [94 calls to valueAt]\n",
      "Iter 81 evals 92 <D> [2M 5,113E-1] 2,466E2 10,92s |2,155E1| {1,367E-3} 3,273E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 82: neg. log cond. likelihood = 241.28057146235915 [95 calls to valueAt]\n",
      "Iter 82 evals 94 <D> [M 1,000E0] 2,413E2 11,01s |1,117E1| {7,085E-4} 3,004E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 83: neg. log cond. likelihood = 240.74548048019003 [96 calls to valueAt]\n",
      "Iter 83 evals 95 <D> [M 1,000E0] 2,407E2 11,10s |3,716E1| {2,358E-3} 2,611E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 84: neg. log cond. likelihood = 233.14360290362032 [97 calls to valueAt]\n",
      "Iter 84 evals 96 <D> [M 1,000E0] 2,331E2 11,18s |7,359E0| {4,669E-4} 2,556E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 85: neg. log cond. likelihood = 229.81202307595362 [98 calls to valueAt]\n",
      "Iter 85 evals 97 <D> [M 1,000E0] 2,298E2 11,27s |8,671E0| {5,502E-4} 2,261E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 86: neg. log cond. likelihood = 223.84790052864346 [99 calls to valueAt]\n",
      "Iter 86 evals 98 <D> [M 1,000E0] 2,238E2 11,36s |1,871E1| {1,187E-3} 2,230E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 87: neg. log cond. likelihood = 218.50665623887025 [100 calls to valueAt]\n",
      "Iter 87 evals 99 <D> [M 1,000E0] 2,185E2 11,44s |1,394E1| {8,845E-4} 2,133E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 88: neg. log cond. likelihood = 214.37124948439472 [101 calls to valueAt]\n",
      "Iter 88 evals 100 <D> [M 1,000E0] 2,144E2 11,53s |9,923E0| {6,296E-4} 2,111E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 89: neg. log cond. likelihood = 209.26450363752738 [102 calls to valueAt]\n",
      "Iter 89 evals 101 <D> [M 1,000E0] 2,093E2 11,61s |1,157E1| {7,339E-4} 1,949E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 90: neg. log cond. likelihood = 207.36092102121313 [103 calls to valueAt]\n",
      "Checking model correctness; x size 34166 , ysize 19\n",
      "Iter 90 evals 102 <D> [M 1,000E0] 2,074E2 11,70s |1,574E1| {9,990E-4} 1,895E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 91: neg. log cond. likelihood = 202.34105953388126 [104 calls to valueAt]\n",
      "Iter 91 evals 103 <D> [M 1,000E0] 2,023E2 11,80s |8,921E0| {5,661E-4} 1,924E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 92: neg. log cond. likelihood = 199.38613841451811 [105 calls to valueAt]\n",
      "Iter 92 evals 104 <D> [M 1,000E0] 1,994E2 11,88s |1,022E1| {6,486E-4} 2,074E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 93: neg. log cond. likelihood = 197.52664916738388 [107 calls to valueAt]\n",
      "Iter 93 evals 105 <D> [2M 5,147E-1] 1,975E2 12,04s |1,491E1| {9,459E-4} 1,803E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 94: neg. log cond. likelihood = 194.07508677425784 [108 calls to valueAt]\n",
      "Iter 94 evals 107 <D> [M 1,000E0] 1,941E2 12,12s |5,782E0| {3,669E-4} 1,841E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 95: neg. log cond. likelihood = 190.59462157316403 [109 calls to valueAt]\n",
      "Iter 95 evals 108 <D> [M 1,000E0] 1,906E2 12,21s |5,538E0| {3,514E-4} 1,745E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 96: neg. log cond. likelihood = 187.75866525041613 [110 calls to valueAt]\n",
      "Iter 96 evals 109 <D> [M 1,000E0] 1,878E2 12,29s |1,043E1| {6,620E-4} 1,638E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 97: neg. log cond. likelihood = 185.38416352503754 [111 calls to valueAt]\n",
      "Iter 97 evals 110 <D> [M 1,000E0] 1,854E2 12,37s |7,329E0| {4,651E-4} 1,564E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 98: neg. log cond. likelihood = 183.14032553651356 [112 calls to valueAt]\n",
      "Iter 98 evals 111 <D> [M 1,000E0] 1,831E2 12,46s |7,732E0| {4,906E-4} 1,426E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 99: neg. log cond. likelihood = 181.92585038171143 [113 calls to valueAt]\n",
      "Iter 99 evals 112 <D> [M 1,000E0] 1,819E2 12,54s |9,972E0| {6,328E-4} 1,398E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 100: neg. log cond. likelihood = 180.06570457691657 [114 calls to valueAt]\n",
      "Iter 100 evals 113 <D> [M 1,000E0] 1,801E2 12,62s |4,449E0| {2,823E-4} 1,237E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 101: neg. log cond. likelihood = 178.49547098943532 [115 calls to valueAt]\n",
      "Iter 101 evals 114 <D> [M 1,000E0] 1,785E2 12,71s |4,999E0| {3,172E-4} 1,170E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 102: neg. log cond. likelihood = 176.9837913131787 [116 calls to valueAt]\n",
      "Iter 102 evals 115 <D> [M 1,000E0] 1,770E2 12,79s |5,239E0| {3,324E-4} 1,161E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 103: neg. log cond. likelihood = 175.18367322299616 [117 calls to valueAt]\n",
      "Iter 103 evals 116 <D> [M 1,000E0] 1,752E2 12,87s |4,678E0| {2,968E-4} 1,078E-2 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 104: neg. log cond. likelihood = 174.5353250424376 [118 calls to valueAt]\n",
      "Iter 104 evals 117 <D> [M 1,000E0] 1,745E2 12,95s |1,507E1| {9,566E-4} 9,201E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 105: neg. log cond. likelihood = 172.842084713009 [119 calls to valueAt]\n",
      "Iter 105 evals 118 <D> [M 1,000E0] 1,728E2 13,04s |6,526E0| {4,141E-4} 8,630E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 106: neg. log cond. likelihood = 172.02168832449124 [120 calls to valueAt]\n",
      "Iter 106 evals 119 <D> [M 1,000E0] 1,720E2 13,12s |5,376E0| {3,411E-4} 7,768E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 107: neg. log cond. likelihood = 171.1743718539904 [121 calls to valueAt]\n",
      "Iter 107 evals 120 <D> [M 1,000E0] 1,712E2 13,20s |2,587E0| {1,641E-4} 6,991E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 108: neg. log cond. likelihood = 169.98077388666053 [122 calls to valueAt]\n",
      "Iter 108 evals 121 <D> [M 1,000E0] 1,700E2 13,29s |3,935E0| {2,497E-4} 7,027E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 109: neg. log cond. likelihood = 169.15551215131325 [123 calls to valueAt]\n",
      "Iter 109 evals 122 <D> [M 1,000E0] 1,692E2 13,37s |7,595E0| {4,820E-4} 6,450E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 110: neg. log cond. likelihood = 168.11982775235765 [124 calls to valueAt]\n",
      "Iter 110 evals 123 <D> [M 1,000E0] 1,681E2 13,45s |4,664E0| {2,959E-4} 6,172E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 111: neg. log cond. likelihood = 167.28195762845587 [125 calls to valueAt]\n",
      "Iter 111 evals 124 <D> [M 1,000E0] 1,673E2 13,53s |4,725E0| {2,998E-4} 5,800E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 112: neg. log cond. likelihood = 166.41485752936626 [126 calls to valueAt]\n",
      "Iter 112 evals 125 <D> [M 1,000E0] 1,664E2 13,62s |4,218E0| {2,676E-4} 5,269E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 113: neg. log cond. likelihood = 165.70724793231858 [127 calls to valueAt]\n",
      "Iter 113 evals 126 <D> [M 1,000E0] 1,657E2 13,70s |3,759E0| {2,385E-4} 5,328E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 114: neg. log cond. likelihood = 165.0704424261712 [128 calls to valueAt]\n",
      "Iter 114 evals 127 <D> [M 1,000E0] 1,651E2 13,78s |2,512E0| {1,594E-4} 4,708E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 115: neg. log cond. likelihood = 164.594269498883 [129 calls to valueAt]\n",
      "Iter 115 evals 128 <D> [M 1,000E0] 1,646E2 13,86s |4,704E0| {2,985E-4} 4,513E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 116: neg. log cond. likelihood = 163.9965747167118 [130 calls to valueAt]\n",
      "Iter 116 evals 129 <D> [M 1,000E0] 1,640E2 13,95s |2,665E0| {1,691E-4} 4,377E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 117: neg. log cond. likelihood = 163.64251858717122 [131 calls to valueAt]\n",
      "Iter 117 evals 130 <D> [M 1,000E0] 1,636E2 14,03s |2,696E0| {1,711E-4} 3,873E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 118: neg. log cond. likelihood = 163.20554204863535 [132 calls to valueAt]\n",
      "Iter 118 evals 131 <D> [M 1,000E0] 1,632E2 14,11s |1,916E0| {1,216E-4} 3,646E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 119: neg. log cond. likelihood = 162.76812408709986 [133 calls to valueAt]\n",
      "Iter 119 evals 132 <D> [M 1,000E0] 1,628E2 14,19s |8,169E0| {5,184E-4} 3,288E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 120: neg. log cond. likelihood = 162.27382679161136 [135 calls to valueAt]\n",
      "Checking model correctness; x size 34166 , ysize 19\n",
      " Lambda too big 100.47446431275274\n",
      " empirical 6.78709407956563E-4 expected 6.787094079516781E-4\n",
      " Lambda too big 101.39082142699317\n",
      " empirical 0.006056176255612415 expected 0.006056176255612415\n",
      " Lambda too big 106.41111117835162\n",
      " empirical 0.00206223243186802 expected 0.00206223243186802\n",
      " Lambda too big 121.42200755911162\n",
      " empirical 0.0016967735198914087 expected 0.0016967735198914087\n",
      " Lambda too big 108.19957441135739\n",
      " empirical 0.001435731439908115 expected 0.0014357314362259442\n",
      " Lambda too big 105.92020483524178\n",
      " empirical 0.01889944659079047 expected 0.018898934915535286\n",
      " Lambda too big 100.8833663364213\n",
      " empirical 0.0018272945598830556 expected 0.0018272945377106418\n",
      "Iter 120 evals 133 <D> [2M 5,147E-1] 1,623E2 14,34s |3,326E0| {2,110E-4} 3,086E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 121: neg. log cond. likelihood = 161.9078421167707 [136 calls to valueAt]\n",
      "Iter 121 evals 135 <D> [M 1,000E0] 1,619E2 14,44s |1,752E0| {1,111E-4} 2,784E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 122: neg. log cond. likelihood = 161.59826215727574 [137 calls to valueAt]\n",
      "Iter 122 evals 136 <D> [M 1,000E0] 1,616E2 14,52s |2,721E0| {1,726E-4} 2,543E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 123: neg. log cond. likelihood = 161.24050055362162 [138 calls to valueAt]\n",
      "Iter 123 evals 137 <D> [M 1,000E0] 1,612E2 14,60s |1,939E0| {1,230E-4} 2,375E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 124: neg. log cond. likelihood = 160.9083413194692 [139 calls to valueAt]\n",
      "Iter 124 evals 138 <D> [M 1,000E0] 1,609E2 14,69s |1,785E0| {1,133E-4} 2,291E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 125: neg. log cond. likelihood = 160.72698906389974 [140 calls to valueAt]\n",
      "Iter 125 evals 139 <D> [M 1,000E0] 1,607E2 14,77s |4,310E0| {2,735E-4} 2,034E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 126: neg. log cond. likelihood = 160.2942919576748 [141 calls to valueAt]\n",
      "Iter 126 evals 140 <D> [M 1,000E0] 1,603E2 14,85s |2,316E0| {1,469E-4} 2,089E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 127: neg. log cond. likelihood = 160.09678186315207 [142 calls to valueAt]\n",
      "Iter 127 evals 141 <D> [M 1,000E0] 1,601E2 14,93s |2,111E0| {1,340E-4} 1,942E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 128: neg. log cond. likelihood = 159.8845926943852 [143 calls to valueAt]\n",
      "Iter 128 evals 142 <D> [M 1,000E0] 1,599E2 15,02s |1,135E0| {7,202E-5} 1,804E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 129: neg. log cond. likelihood = 159.71619334271736 [145 calls to valueAt]\n",
      "Iter 129 evals 143 <D> [1M 4,228E-1] 1,597E2 15,17s |2,003E0| {1,271E-4} 1,601E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 130: neg. log cond. likelihood = 159.46454239433737 [146 calls to valueAt]\n",
      "Iter 130 evals 145 <D> [M 1,000E0] 1,595E2 15,25s |1,436E0| {9,113E-5} 1,532E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 131: neg. log cond. likelihood = 159.25811117663744 [147 calls to valueAt]\n",
      "Iter 131 evals 146 <D> [M 1,000E0] 1,593E2 15,33s |1,408E0| {8,937E-5} 1,469E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 132: neg. log cond. likelihood = 159.14502709524317 [148 calls to valueAt]\n",
      "Iter 132 evals 147 <D> [M 1,000E0] 1,591E2 15,41s |3,454E0| {2,191E-4} 1,317E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 133: neg. log cond. likelihood = 158.88216469822106 [149 calls to valueAt]\n",
      "Iter 133 evals 148 <D> [M 1,000E0] 1,589E2 15,50s |1,258E0| {7,982E-5} 1,275E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 134: neg. log cond. likelihood = 158.76857910681946 [150 calls to valueAt]\n",
      "Iter 134 evals 149 <D> [M 1,000E0] 1,588E2 15,58s |1,695E0| {1,076E-4} 1,233E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 135: neg. log cond. likelihood = 158.63700887176188 [151 calls to valueAt]\n",
      "Iter 135 evals 150 <D> [M 1,000E0] 1,586E2 15,66s |1,999E0| {1,269E-4} 1,045E-3 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 136: neg. log cond. likelihood = 158.51734685783708 [152 calls to valueAt]\n",
      "Iter 136 evals 151 <D> [M 1,000E0] 1,585E2 15,74s |3,996E0| {2,536E-4} 9,964E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 137: neg. log cond. likelihood = 158.34708222826498 [153 calls to valueAt]\n",
      "Iter 137 evals 152 <D> [M 1,000E0] 1,583E2 15,82s |1,036E0| {6,575E-5} 9,710E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 138: neg. log cond. likelihood = 158.27895671425534 [154 calls to valueAt]\n",
      "Iter 138 evals 153 <D> [M 1,000E0] 1,583E2 15,90s |9,019E-1| {5,723E-5} 9,080E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 139: neg. log cond. likelihood = 158.16466062198495 [155 calls to valueAt]\n",
      "Iter 139 evals 154 <D> [M 1,000E0] 1,582E2 15,99s |1,883E0| {1,195E-4} 8,219E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 140: neg. log cond. likelihood = 158.0210926319284 [156 calls to valueAt]\n",
      "Iter 140 evals 155 <D> [M 1,000E0] 1,580E2 16,07s |1,596E0| {1,012E-4} 7,828E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 141: neg. log cond. likelihood = 157.91511018905828 [157 calls to valueAt]\n",
      "Iter 141 evals 156 <D> [M 1,000E0] 1,579E2 16,15s |1,683E0| {1,068E-4} 7,788E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 142: neg. log cond. likelihood = 157.7801049265893 [158 calls to valueAt]\n",
      "Iter 142 evals 157 <D> [M 1,000E0] 1,578E2 16,23s |9,004E-1| {5,714E-5} 6,985E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 143: neg. log cond. likelihood = 157.69719906532436 [159 calls to valueAt]\n",
      "Iter 143 evals 158 <D> [M 1,000E0] 1,577E2 16,31s |2,367E0| {1,502E-4} 6,794E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 144: neg. log cond. likelihood = 157.5432850291878 [160 calls to valueAt]\n",
      "Iter 144 evals 159 <D> [M 1,000E0] 1,575E2 16,39s |1,137E0| {7,218E-5} 6,942E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 145: neg. log cond. likelihood = 157.46648788201088 [161 calls to valueAt]\n",
      "Iter 145 evals 160 <D> [M 1,000E0] 1,575E2 16,48s |1,228E0| {7,789E-5} 6,674E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 146: neg. log cond. likelihood = 157.36267697785047 [162 calls to valueAt]\n",
      "Iter 146 evals 161 <D> [M 1,000E0] 1,574E2 16,56s |1,033E0| {6,556E-5} 6,256E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 147: neg. log cond. likelihood = 157.32099310111795 [163 calls to valueAt]\n",
      "Iter 147 evals 162 <D> [M 1,000E0] 1,573E2 16,64s |2,747E0| {1,743E-4} 6,089E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 148: neg. log cond. likelihood = 157.17692313701372 [164 calls to valueAt]\n",
      "Iter 148 evals 163 <D> [M 1,000E0] 1,572E2 16,72s |1,805E0| {1,146E-4} 6,284E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 149: neg. log cond. likelihood = 157.14973543716016 [165 calls to valueAt]\n",
      "Iter 149 evals 164 <D> [M 1,000E0] 1,571E2 16,80s |2,244E0| {1,424E-4} 5,545E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 150: neg. log cond. likelihood = 157.04078026422474 [166 calls to valueAt]\n",
      "Checking model correctness; x size 34166 , ysize 19\n",
      " Lambda too big 107.15032623939523\n",
      " empirical 6.265009919599042E-4 expected 6.265009919599042E-4\n",
      " Lambda too big 114.36436128574425\n",
      " empirical 7.309178239532217E-4 expected 7.309178239531593E-4\n",
      " Lambda too big 105.11848781299727\n",
      " empirical 0.00289756708781456 expected 0.0028975133082734905\n",
      " Lambda too big 114.44796329012817\n",
      " empirical 0.0018011903518847263 expected 0.0018011903518841922\n",
      " Lambda too big 105.8312144966605\n",
      " empirical 4.959799519682573E-4 expected 4.959799489262213E-4\n",
      " Lambda too big 100.27989939026257\n",
      " empirical 0.008092304479482105 expected 0.008092304479478885\n",
      " Lambda too big 108.55398705504578\n",
      " empirical 3.6545891197661064E-4 expected 3.6545891197661064E-4\n",
      " Lambda too big 106.36643391848382\n",
      " empirical 0.0011485851519264917 expected 0.0011485851518820778\n",
      " Lambda too big 101.75527732035047\n",
      " empirical 2.0883366398663465E-4 expected 2.0883366398663465E-4\n",
      " Lambda too big 119.85674272785253\n",
      " empirical 6.78709407956563E-4 expected 6.78709407956409E-4\n",
      " Lambda too big 117.44178225650748\n",
      " empirical 0.0408269813093859 expected 0.040826964987099694\n",
      " Lambda too big 119.74172462484866\n",
      " empirical 0.006056176255612415 expected 0.006056176255612415\n",
      " Lambda too big 112.92669304788178\n",
      " empirical 0.006056176255612415 expected 0.006056176217344328\n",
      " Lambda too big 126.28435839312861\n",
      " empirical 0.00206223243186802 expected 0.00206223243186802\n",
      " Lambda too big 115.73782457570594\n",
      " empirical 0.0019578155998747023 expected 0.0019578155998747023\n",
      " Lambda too big 144.19006060296445\n",
      " empirical 0.0016967735198914087 expected 0.0016967735198914087\n",
      " Lambda too big 109.08577842987287\n",
      " empirical 0.001514044063903103 expected 0.0015140440638741314\n",
      " Lambda too big 109.68435209587975\n",
      " empirical 0.00498590372768091 expected 0.00498590372768091\n",
      " Lambda too big 113.82999421767965\n",
      " empirical 0.002271066095854655 expected 0.002271066095854655\n",
      " Lambda too big 128.68261123892225\n",
      " empirical 0.001435731439908115 expected 0.0014357314397747548\n",
      " Lambda too big 100.02593239953805\n",
      " empirical 7.048136159548923E-4 expected 7.048136159548923E-4\n",
      " Lambda too big 126.41943137044748\n",
      " empirical 0.01889944659079047 expected 0.018899325816293337\n",
      " Lambda too big 120.19475118358096\n",
      " empirical 0.0018272945598830556 expected 0.0018272945563308856\n",
      " Lambda too big 100.81558585350804\n",
      " empirical 6.265009919599042E-4 expected 6.265008972175427E-4\n",
      " Lambda too big 107.82359410548537\n",
      " empirical 0.0012791061919181386 expected 0.0012791061919181386\n",
      "Iter 150 evals 165 <D> [M 1,000E0] 1,570E2 16,88s |7,543E-1| {4,786E-5} 5,568E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 151: neg. log cond. likelihood = 156.93334011402212 [167 calls to valueAt]\n",
      "Iter 151 evals 166 <D> [M 1,000E0] 1,569E2 16,98s |9,618E-1| {6,103E-5} 5,396E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 152: neg. log cond. likelihood = 156.8666940322377 [169 calls to valueAt]\n",
      "Iter 152 evals 167 <D> [2M 5,125E-1] 1,569E2 17,13s |1,670E0| {1,060E-4} 5,294E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 153: neg. log cond. likelihood = 156.72989654029186 [170 calls to valueAt]\n",
      "Iter 153 evals 169 <D> [M 1,000E0] 1,567E2 17,21s |1,489E0| {9,449E-5} 5,190E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 154: neg. log cond. likelihood = 156.64160764542086 [171 calls to valueAt]\n",
      "Iter 154 evals 170 <D> [M 1,000E0] 1,566E2 17,29s |8,424E-1| {5,345E-5} 5,266E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 155: neg. log cond. likelihood = 156.48499667238184 [172 calls to valueAt]\n",
      "Iter 155 evals 171 <D> [M 1,000E0] 1,565E2 17,37s |1,491E0| {9,462E-5} 5,609E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 156: neg. log cond. likelihood = 156.45712722031723 [173 calls to valueAt]\n",
      "Iter 156 evals 172 <D> [M 1,000E0] 1,565E2 17,45s |2,616E0| {1,660E-4} 5,521E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 157: neg. log cond. likelihood = 156.3418468083048 [174 calls to valueAt]\n",
      "Iter 157 evals 173 <D> [M 1,000E0] 1,563E2 17,53s |8,763E-1| {5,560E-5} 5,341E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 158: neg. log cond. likelihood = 156.28418350918727 [175 calls to valueAt]\n",
      "Iter 158 evals 174 <D> [M 1,000E0] 1,563E2 17,61s |1,164E0| {7,384E-5} 5,538E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 159: neg. log cond. likelihood = 156.21503090936952 [176 calls to valueAt]\n",
      "Iter 159 evals 175 <D> [M 1,000E0] 1,562E2 17,70s |1,239E0| {7,861E-5} 5,286E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 160: neg. log cond. likelihood = 156.17837344416088 [177 calls to valueAt]\n",
      "Iter 160 evals 176 <D> [M 1,000E0] 1,562E2 17,78s |1,352E0| {8,578E-5} 4,834E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 161: neg. log cond. likelihood = 156.11469677003953 [178 calls to valueAt]\n",
      "Iter 161 evals 177 <D> [M 1,000E0] 1,561E2 17,86s |4,825E-1| {3,062E-5} 4,817E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 162: neg. log cond. likelihood = 156.07513948500647 [179 calls to valueAt]\n",
      "Iter 162 evals 178 <D> [M 1,000E0] 1,561E2 17,94s |8,605E-1| {5,460E-5} 4,195E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 163: neg. log cond. likelihood = 156.03833172571666 [180 calls to valueAt]\n",
      "Iter 163 evals 179 <D> [M 1,000E0] 1,560E2 18,03s |2,095E0| {1,329E-4} 3,866E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 164: neg. log cond. likelihood = 155.98027245465954 [181 calls to valueAt]\n",
      "Iter 164 evals 180 <D> [M 1,000E0] 1,560E2 18,11s |1,031E0| {6,541E-5} 3,236E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 165: neg. log cond. likelihood = 155.92702706135628 [182 calls to valueAt]\n",
      "Iter 165 evals 181 <D> [M 1,000E0] 1,559E2 18,19s |8,545E-1| {5,422E-5} 3,400E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 166: neg. log cond. likelihood = 155.87739280219907 [183 calls to valueAt]\n",
      "Iter 166 evals 182 <D> [M 1,000E0] 1,559E2 18,27s |1,601E0| {1,016E-4} 2,980E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 167: neg. log cond. likelihood = 155.83270679131527 [184 calls to valueAt]\n",
      "Iter 167 evals 183 <D> [M 1,000E0] 1,558E2 18,36s |1,163E0| {7,379E-5} 2,897E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 168: neg. log cond. likelihood = 155.78599404355953 [185 calls to valueAt]\n",
      "Iter 168 evals 184 <D> [M 1,000E0] 1,558E2 18,44s |6,128E-1| {3,889E-5} 2,754E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 169: neg. log cond. likelihood = 155.74625322310385 [186 calls to valueAt]\n",
      "Iter 169 evals 185 <D> [M 1,000E0] 1,557E2 18,52s |6,064E-1| {3,848E-5} 2,775E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 170: neg. log cond. likelihood = 155.67251821848993 [187 calls to valueAt]\n",
      "Iter 170 evals 186 <D> [M 1,000E0] 1,557E2 18,60s |1,105E0| {7,009E-5} 2,840E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 171: neg. log cond. likelihood = 155.6273016903384 [188 calls to valueAt]\n",
      "Iter 171 evals 187 <D> [M 1,000E0] 1,556E2 18,68s |1,238E0| {7,853E-5} 2,878E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 172: neg. log cond. likelihood = 155.5921862964877 [189 calls to valueAt]\n",
      "Iter 172 evals 188 <D> [M 1,000E0] 1,556E2 18,76s |1,233E0| {7,826E-5} 2,867E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 173: neg. log cond. likelihood = 155.54135809411417 [190 calls to valueAt]\n",
      "Iter 173 evals 189 <D> [M 1,000E0] 1,555E2 18,84s |5,210E-1| {3,306E-5} 2,822E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 174: neg. log cond. likelihood = 155.50393090681567 [191 calls to valueAt]\n",
      "Iter 174 evals 190 <D> [M 1,000E0] 1,555E2 18,93s |6,264E-1| {3,975E-5} 2,721E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 175: neg. log cond. likelihood = 155.44849899090127 [192 calls to valueAt]\n",
      "Iter 175 evals 191 <D> [M 1,000E0] 1,554E2 19,01s |1,435E0| {9,105E-5} 2,759E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 176: neg. log cond. likelihood = 155.42569301858921 [193 calls to valueAt]\n",
      "Iter 176 evals 192 <D> [M 1,000E0] 1,554E2 19,09s |2,510E0| {1,592E-4} 2,619E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 177: neg. log cond. likelihood = 155.3645474297863 [194 calls to valueAt]\n",
      "Iter 177 evals 193 <D> [M 1,000E0] 1,554E2 19,17s |6,212E-1| {3,942E-5} 2,713E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 178: neg. log cond. likelihood = 155.33741791886098 [195 calls to valueAt]\n",
      "Iter 178 evals 194 <D> [M 1,000E0] 1,553E2 19,25s |7,414E-1| {4,705E-5} 2,632E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 179: neg. log cond. likelihood = 155.29227547739308 [196 calls to valueAt]\n",
      "Iter 179 evals 195 <D> [M 1,000E0] 1,553E2 19,34s |8,176E-1| {5,188E-5} 2,449E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 180: neg. log cond. likelihood = 155.2426864321171 [198 calls to valueAt]\n",
      "Checking model correctness; x size 34166 , ysize 19\n",
      " Lambda too big 121.71798968460399\n",
      " empirical 6.265009919599042E-4 expected 6.265009919599042E-4\n",
      " Lambda too big 103.17842762879559\n",
      " empirical 6.526051999582336E-4 expected 6.526051999535019E-4\n",
      " Lambda too big 129.9823228852739\n",
      " empirical 7.309178239532217E-4 expected 7.309178239532173E-4\n",
      " Lambda too big 111.32909325612145\n",
      " empirical 2.3493787198496398E-4 expected 2.3493787198496398E-4\n",
      " Lambda too big 119.98551095399944\n",
      " empirical 0.00289756708781456 expected 0.002897352542552072\n",
      " Lambda too big 106.29050746689309\n",
      " empirical 7.309178239532217E-4 expected 7.309178239532217E-4\n",
      " Lambda too big 129.5208463360999\n",
      " empirical 0.0018011903518847263 expected 0.0018011903518846781\n",
      " Lambda too big 120.77016636938441\n",
      " empirical 4.959799519682573E-4 expected 4.95979950722417E-4\n",
      " Lambda too big 105.1971611399487\n",
      " empirical 3.393547039782813E-4 expected 3.393547039782813E-4\n",
      " Lambda too big 102.15549084853953\n",
      " empirical 0.006186697295604062 expected 0.006186697295604053\n",
      " Lambda too big 100.84345467947463\n",
      " empirical 0.002140545055863008 expected 0.002140545053965213\n",
      " Lambda too big 107.8516866085537\n",
      " empirical 9.397514879398568E-4 expected 9.397514879312579E-4\n",
      " Lambda too big 106.44222899250592\n",
      " empirical 0.0012268977759214799 expected 0.0012268977759214799\n",
      " Lambda too big 110.38259332796144\n",
      " empirical 7.831262399498805E-4 expected 7.831262399496579E-4\n",
      " Lambda too big 106.7414800259468\n",
      " empirical 6.78709407956563E-4 expected 6.78709407956563E-4\n",
      " Lambda too big 113.42075784496606\n",
      " empirical 0.008092304479482105 expected 0.00809230447948223\n",
      " Lambda too big 123.59669256213213\n",
      " empirical 3.6545891197661064E-4 expected 3.6545891197661064E-4\n",
      " Lambda too big 120.94729191953643\n",
      " empirical 0.0011485851519264917 expected 0.001148585151910549\n",
      " Lambda too big 116.21277252997088\n",
      " empirical 2.0883366398663465E-4 expected 2.0883366398663465E-4\n",
      " Lambda too big 101.55711561817266\n",
      " empirical 0.001853398767881385 expected 0.001853398767881385\n",
      " Lambda too big 112.916881811671\n",
      " empirical 0.025477707006369463 expected 0.025477707005857178\n",
      " Lambda too big 102.98314386010912\n",
      " empirical 5.220841599665867E-4 expected 5.220841599665867E-4\n",
      " Lambda too big 109.24135959025065\n",
      " empirical 4.176673279732693E-4 expected 4.176673279708417E-4\n",
      " Lambda too big 136.18394170269238\n",
      " empirical 6.78709407956563E-4 expected 6.787094079565469E-4\n",
      " Lambda too big 101.17591689017193\n",
      " empirical 9.136472799415274E-4 expected 9.12930622242042E-4\n",
      " Lambda too big 106.50110428282018\n",
      " empirical 0.0026626292158295956 expected 0.0026626292158295956\n",
      " Lambda too big 133.29529692539703\n",
      " empirical 0.0408269813093859 expected 0.040826971265477525\n",
      " Lambda too big 135.20011617814728\n",
      " empirical 0.006056176255612415 expected 0.006056176255612415\n",
      " Lambda too big 127.66725112090786\n",
      " empirical 0.006056176255612415 expected 0.006056176182931848\n",
      " Lambda too big 143.02513855419792\n",
      " empirical 0.00206223243186802 expected 0.00206223243186802\n",
      " Lambda too big 131.0794446015086\n",
      " empirical 0.0019578155998747023 expected 0.0019578155998747023\n",
      " Lambda too big 163.36936061546632\n",
      " empirical 0.0016967735198914087 expected 0.0016967735198914087\n",
      " Lambda too big 123.71106165970888\n",
      " empirical 0.001514044063903103 expected 0.00151404406387877\n",
      " Lambda too big 123.72488614636424\n",
      " empirical 0.00498590372768091 expected 0.00498590372768091\n",
      " Lambda too big 129.32747370637966\n",
      " empirical 0.002271066095854655 expected 0.002271066095854655\n",
      " Lambda too big 145.9370660384155\n",
      " empirical 0.001435731439908115 expected 0.001435731439900998\n",
      " Lambda too big 113.65739347853147\n",
      " empirical 7.048136159548923E-4 expected 7.048136159548923E-4\n",
      " Lambda too big 103.81739150187875\n",
      " empirical 0.00498590372768091 expected 0.00498590379905919\n",
      " Lambda too big 144.82654801966663\n",
      " empirical 0.01889944659079047 expected 0.01889943778164338\n",
      " Lambda too big 136.4622553594095\n",
      " empirical 0.0018272945598830556 expected 0.001827294559562885\n",
      " Lambda too big 109.55473157665395\n",
      " empirical 0.0014879398559047737 expected 0.001487936269203087\n",
      " Lambda too big 114.68940696191952\n",
      " empirical 6.265009919599042E-4 expected 6.265009405081624E-4\n",
      " Lambda too big 122.17203756476611\n",
      " empirical 0.0012791061919181386 expected 0.0012791061919181386\n",
      " Lambda too big 100.17865491204765\n",
      " empirical 2.610420799832933E-5 expected 2.609057739010063E-5\n",
      "Iter 180 evals 196 <D> [1M 4,611E-1] 1,552E2 19,50s |1,474E0| {9,354E-5} 2,478E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 181: neg. log cond. likelihood = 155.19621285503692 [199 calls to valueAt]\n",
      "Iter 181 evals 198 <D> [M 1,000E0] 1,552E2 19,59s |5,160E-1| {3,274E-5} 2,551E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 182: neg. log cond. likelihood = 155.16309290224044 [200 calls to valueAt]\n",
      "Iter 182 evals 199 <D> [M 1,000E0] 1,552E2 19,68s |6,623E-1| {4,202E-5} 2,438E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 183: neg. log cond. likelihood = 155.1156454925467 [201 calls to valueAt]\n",
      "Iter 183 evals 200 <D> [M 1,000E0] 1,551E2 19,76s |1,142E0| {7,249E-5} 2,503E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 184: neg. log cond. likelihood = 155.08255981997397 [202 calls to valueAt]\n",
      "Iter 184 evals 201 <D> [M 1,000E0] 1,551E2 19,84s |1,204E0| {7,640E-5} 2,360E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 185: neg. log cond. likelihood = 155.03693341235402 [203 calls to valueAt]\n",
      "Iter 185 evals 202 <D> [M 1,000E0] 1,550E2 19,93s |4,374E-1| {2,775E-5} 2,508E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 186: neg. log cond. likelihood = 155.00956830341983 [204 calls to valueAt]\n",
      "Iter 186 evals 203 <D> [M 1,000E0] 1,550E2 20,01s |7,539E-1| {4,784E-5} 2,290E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 187: neg. log cond. likelihood = 154.9700789563476 [205 calls to valueAt]\n",
      "Iter 187 evals 204 <D> [M 1,000E0] 1,550E2 20,09s |6,663E-1| {4,228E-5} 2,370E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 188: neg. log cond. likelihood = 154.95686015074213 [206 calls to valueAt]\n",
      "Iter 188 evals 205 <D> [M 1,000E0] 1,550E2 20,17s |1,559E0| {9,890E-5} 2,165E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 189: neg. log cond. likelihood = 154.89080293683534 [207 calls to valueAt]\n",
      "Iter 189 evals 206 <D> [M 1,000E0] 1,549E2 20,25s |5,912E-1| {3,752E-5} 2,272E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 190: neg. log cond. likelihood = 154.87840051244007 [208 calls to valueAt]\n",
      "Iter 190 evals 207 <D> [M 1,000E0] 1,549E2 20,34s |1,291E0| {8,191E-5} 2,052E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 191: neg. log cond. likelihood = 154.84220140013593 [209 calls to valueAt]\n",
      "Iter 191 evals 208 <D> [M 1,000E0] 1,548E2 20,42s |4,386E-1| {2,783E-5} 2,072E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 192: neg. log cond. likelihood = 154.80491305526658 [210 calls to valueAt]\n",
      "Iter 192 evals 209 <D> [M 1,000E0] 1,548E2 20,50s |6,891E-1| {4,372E-5} 2,007E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 193: neg. log cond. likelihood = 154.76354843917593 [211 calls to valueAt]\n",
      "Iter 193 evals 210 <D> [M 1,000E0] 1,548E2 20,58s |1,098E0| {6,969E-5} 2,061E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 194: neg. log cond. likelihood = 154.725580341007 [212 calls to valueAt]\n",
      "Iter 194 evals 211 <D> [M 1,000E0] 1,547E2 20,66s |9,696E-1| {6,153E-5} 2,012E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 195: neg. log cond. likelihood = 154.66696301870005 [213 calls to valueAt]\n",
      "Iter 195 evals 212 <D> [M 1,000E0] 1,547E2 20,75s |5,237E-1| {3,323E-5} 2,215E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 196: neg. log cond. likelihood = 154.64455706995426 [214 calls to valueAt]\n",
      "Iter 196 evals 213 <D> [M 1,000E0] 1,546E2 20,83s |2,022E0| {1,283E-4} 2,105E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 197: neg. log cond. likelihood = 154.6002570719524 [215 calls to valueAt]\n",
      "Iter 197 evals 214 <D> [M 1,000E0] 1,546E2 20,91s |1,090E0| {6,919E-5} 2,307E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 198: neg. log cond. likelihood = 154.56481559888394 [216 calls to valueAt]\n",
      "Iter 198 evals 215 <D> [M 1,000E0] 1,546E2 21,00s |7,081E-1| {4,493E-5} 2,109E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 199: neg. log cond. likelihood = 154.53190113252282 [217 calls to valueAt]\n",
      "Iter 199 evals 216 <D> [M 1,000E0] 1,545E2 21,08s |4,613E-1| {2,927E-5} 2,242E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 200: neg. log cond. likelihood = 154.46841154681965 [218 calls to valueAt]\n",
      "Iter 200 evals 217 <D> [M 1,000E0] 1,545E2 21,17s |9,443E-1| {5,992E-5} 2,420E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 201: neg. log cond. likelihood = 154.41374055280895 [219 calls to valueAt]\n",
      "Iter 201 evals 218 <D> [M 1,000E0] 1,544E2 21,26s |9,528E-1| {6,046E-5} 2,533E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 202: neg. log cond. likelihood = 154.38769458054298 [220 calls to valueAt]\n",
      "Iter 202 evals 219 <D> [M 1,000E0] 1,544E2 21,34s |1,656E0| {1,051E-4} 2,434E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 203: neg. log cond. likelihood = 154.30962468732685 [221 calls to valueAt]\n",
      "Iter 203 evals 220 <D> [M 1,000E0] 1,543E2 21,42s |7,973E-1| {5,059E-5} 2,696E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 204: neg. log cond. likelihood = 154.2820855648077 [222 calls to valueAt]\n",
      "Iter 204 evals 221 <D> [M 1,000E0] 1,543E2 21,51s |6,585E-1| {4,179E-5} 2,495E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 205: neg. log cond. likelihood = 154.24900815600415 [223 calls to valueAt]\n",
      "Iter 205 evals 222 <D> [M 1,000E0] 1,542E2 21,59s |5,284E-1| {3,353E-5} 2,564E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 206: neg. log cond. likelihood = 154.2067789298472 [225 calls to valueAt]\n",
      "Iter 206 evals 223 <D> [2M 5,139E-1] 1,542E2 21,76s |8,510E-1| {5,400E-5} 2,552E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 207: neg. log cond. likelihood = 154.15874763237753 [226 calls to valueAt]\n",
      "Iter 207 evals 225 <D> [M 1,000E0] 1,542E2 21,85s |6,229E-1| {3,952E-5} 2,634E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 208: neg. log cond. likelihood = 154.11105810601393 [227 calls to valueAt]\n",
      "Iter 208 evals 226 <D> [M 1,000E0] 1,541E2 21,93s |8,395E-1| {5,327E-5} 2,731E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 209: neg. log cond. likelihood = 154.08299695081905 [228 calls to valueAt]\n",
      "Iter 209 evals 227 <D> [M 1,000E0] 1,541E2 22,02s |2,673E0| {1,696E-4} 2,501E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 210: neg. log cond. likelihood = 154.0086808377135 [229 calls to valueAt]\n",
      "Checking model correctness; x size 34166 , ysize 19\n",
      " Lambda too big 130.5698313797459\n",
      " empirical 6.265009919599042E-4 expected 6.265009919599042E-4\n",
      " Lambda too big 107.78177713016257\n",
      " empirical 1.8272945598830532E-4 expected 1.8272945598830532E-4\n",
      " Lambda too big 101.75602169284977\n",
      " empirical 5.220841599665867E-4 expected 5.220841598529666E-4\n",
      " Lambda too big 110.65975989115142\n",
      " empirical 6.526051999582336E-4 expected 6.526051999561362E-4\n",
      " Lambda too big 139.4723639063816\n",
      " empirical 7.309178239532217E-4 expected 7.309178239532217E-4\n",
      " Lambda too big 119.9300236374355\n",
      " empirical 2.3493787198496398E-4 expected 2.3493787198496398E-4\n",
      " Lambda too big 128.98333542025497\n",
      " empirical 0.00289756708781456 expected 0.002897600910177737\n",
      " Lambda too big 114.00046432683753\n",
      " empirical 7.309178239532217E-4 expected 7.309178239532217E-4\n",
      " Lambda too big 138.67967782134141\n",
      " empirical 0.0018011903518847263 expected 0.0018011903518847085\n",
      " Lambda too big 129.8476320291757\n",
      " empirical 4.959799519682573E-4 expected 4.959799515516583E-4\n",
      " Lambda too big 113.01799166146982\n",
      " empirical 3.393547039782813E-4 expected 3.393547039782813E-4\n",
      " Lambda too big 102.89820415759732\n",
      " empirical 0.0036023807037694534 expected 0.003602380703769404\n",
      " Lambda too big 110.19226055887168\n",
      " empirical 0.006186697295604062 expected 0.006186697295604062\n",
      " Lambda too big 104.38553044990239\n",
      " empirical 3.13250495979952E-4 expected 3.132504959799438E-4\n",
      " Lambda too big 104.8588227323817\n",
      " empirical 0.010337266367338432 expected 0.010337266367338449\n",
      " Lambda too big 102.73653966387528\n",
      " empirical 2.3493787198496398E-4 expected 2.3493787198496398E-4\n",
      " Lambda too big 103.85992329617152\n",
      " empirical 2.8714628798162266E-4 expected 2.871462879116987E-4\n",
      " Lambda too big 107.94946158024648\n",
      " empirical 0.002140545055863008 expected 0.00214054505438479\n",
      " Lambda too big 115.62676792512231\n",
      " empirical 9.397514879398568E-4 expected 9.397514879377934E-4\n",
      " Lambda too big 114.14805837356195\n",
      " empirical 0.0012268977759214799 expected 0.0012268977759214799\n",
      " Lambda too big 104.0557586018339\n",
      " empirical 0.0021144408478646786 expected 0.0021144408478646786\n",
      " Lambda too big 104.87757013438305\n",
      " empirical 0.004855382687689262 expected 0.004855382392769977\n",
      " Lambda too big 118.60686861678154\n",
      " empirical 7.831262399498805E-4 expected 7.831262399494787E-4\n",
      " Lambda too big 114.50376254345431\n",
      " empirical 6.78709407956563E-4 expected 6.78709407956563E-4\n",
      " Lambda too big 121.40562093512689\n",
      " empirical 0.008092304479482105 expected 0.008092304479482162\n",
      " Lambda too big 132.73718707727986\n",
      " empirical 3.6545891197661064E-4 expected 3.6545891197661064E-4\n",
      " Lambda too big 129.8071513149701\n",
      " empirical 0.0011485851519264917 expected 0.0011485851519205052\n",
      " Lambda too big 124.99767200191016\n",
      " empirical 2.0883366398663465E-4 expected 2.0883366398663465E-4\n",
      " Lambda too big 103.50403281745776\n",
      " empirical 1.8272945598830532E-4 expected 1.8272933757186086E-4\n",
      " Lambda too big 108.84756042530935\n",
      " empirical 0.001853398767881385 expected 0.001853398767881385\n",
      " Lambda too big 121.26353051309225\n",
      " empirical 0.025477707006369463 expected 0.02547770700619855\n",
      " Lambda too big 110.52558461112122\n",
      " empirical 5.220841599665867E-4 expected 5.220841599665867E-4\n",
      " Lambda too big 117.25731204919002\n",
      " empirical 4.176673279732693E-4 expected 4.1766732797255556E-4\n",
      " Lambda too big 146.10494112724643\n",
      " empirical 6.78709407956563E-4 expected 6.787094079565599E-4\n",
      " Lambda too big 104.98472115899833\n",
      " empirical 9.136472799415274E-4 expected 9.131006473933123E-4\n",
      " Lambda too big 114.04516593760515\n",
      " empirical 0.0026626292158295956 expected 0.0026626292158295956\n",
      " Lambda too big 143.11258032507718\n",
      " empirical 0.0408269813093859 expected 0.04082697317262882\n",
      " Lambda too big 144.59319664102722\n",
      " empirical 0.006056176255612415 expected 0.006056176255612415\n",
      " Lambda too big 136.62519080596263\n",
      " empirical 0.006056176255612415 expected 0.006056176153662317\n",
      " Lambda too big 153.19744493671618\n",
      " empirical 0.00206223243186802 expected 0.00206223243186802\n",
      " Lambda too big 140.40157044063673\n",
      " empirical 0.0019578155998747023 expected 0.0019578155998747023\n",
      " Lambda too big 101.58728036703565\n",
      " empirical 0.00415056907173437 expected 0.00415056907173305\n",
      " Lambda too big 175.0234002750211\n",
      " empirical 0.0016967735198914087 expected 0.0016967735198914087\n",
      " Lambda too big 132.59791555578133\n",
      " empirical 0.001514044063903103 expected 0.0015140440638838366\n",
      " Lambda too big 132.25642486586239\n",
      " empirical 0.00498590372768091 expected 0.00498590372768091\n",
      " Lambda too big 138.7443054190525\n",
      " empirical 0.002271066095854655 expected 0.002271066095854655\n",
      " Lambda too big 102.96265949962569\n",
      " empirical 0.0015662524798997618 expected 0.0015662524794294937\n",
      " Lambda too big 156.42149997004594\n",
      " empirical 0.001435731439908115 expected 0.0014357314399068024\n",
      " Lambda too big 121.94036459465944\n",
      " empirical 7.048136159548923E-4 expected 7.048136159548923E-4\n",
      " Lambda too big 100.74997070614688\n",
      " empirical 2.6104207998329333E-4 expected 2.6030671424623E-4\n",
      " Lambda too big 111.76285222049025\n",
      " empirical 0.00498590372768091 expected 0.004985903755695659\n",
      " Lambda too big 105.52357882087382\n",
      " empirical 7.048136159548923E-4 expected 7.048136159548923E-4\n",
      " Lambda too big 100.69726133009192\n",
      " empirical 2.3493787198496398E-4 expected 2.3493787198496398E-4\n",
      " Lambda too big 156.25366376907883\n",
      " empirical 0.01889944659079047 expected 0.018899444952607185\n",
      " Lambda too big 146.34698889520698\n",
      " empirical 0.0018272945598830556 expected 0.0018272945596993302\n",
      " Lambda too big 117.82492377391745\n",
      " empirical 0.0014879398559047737 expected 0.0014879385289527226\n",
      " Lambda too big 104.64989942561579\n",
      " empirical 0.018560091886812187 expected 0.018560091887037403\n",
      " Lambda too big 123.1202919104151\n",
      " empirical 6.265009919599042E-4 expected 6.265009664264044E-4\n",
      " Lambda too big 101.47063483427435\n",
      " empirical 0.0023232745118513137 expected 0.0023232741290923303\n",
      " Lambda too big 130.8906732301906\n",
      " empirical 0.0012791061919181386 expected 0.0012791061919181386\n",
      " Lambda too big 108.59229596640836\n",
      " empirical 2.610420799832933E-5 expected 2.6098287706912076E-5\n",
      "Iter 210 evals 228 <D> [M 1,000E0] 1,540E2 22,11s |8,767E-1| {5,563E-5} 2,630E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 211: neg. log cond. likelihood = 153.97219417289185 [230 calls to valueAt]\n",
      "Iter 211 evals 229 <D> [M 1,000E0] 1,540E2 22,21s |6,397E-1| {4,059E-5} 2,699E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 212: neg. log cond. likelihood = 153.93466160481773 [231 calls to valueAt]\n",
      "Iter 212 evals 230 <D> [M 1,000E0] 1,539E2 22,30s |6,939E-1| {4,403E-5} 2,436E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 213: neg. log cond. likelihood = 153.87865193980355 [233 calls to valueAt]\n",
      "Iter 213 evals 231 <D> [1M 4,216E-1] 1,539E2 22,45s |1,012E0| {6,422E-5} 2,622E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 214: neg. log cond. likelihood = 153.84040355610614 [234 calls to valueAt]\n",
      "Iter 214 evals 233 <D> [M 1,000E0] 1,538E2 22,54s |5,491E-1| {3,484E-5} 2,656E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 215: neg. log cond. likelihood = 153.81611567651277 [235 calls to valueAt]\n",
      "Iter 215 evals 234 <D> [M 1,000E0] 1,538E2 22,62s |5,193E-1| {3,295E-5} 2,540E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 216: neg. log cond. likelihood = 153.77778568463273 [236 calls to valueAt]\n",
      "Iter 216 evals 235 <D> [M 1,000E0] 1,538E2 22,70s |7,008E-1| {4,447E-5} 2,477E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 217: neg. log cond. likelihood = 153.73274952723978 [237 calls to valueAt]\n",
      "Iter 217 evals 236 <D> [M 1,000E0] 1,537E2 22,78s |9,788E-1| {6,211E-5} 2,461E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 218: neg. log cond. likelihood = 153.70346805065282 [238 calls to valueAt]\n",
      "Iter 218 evals 237 <D> [M 1,000E0] 1,537E2 22,86s |6,675E-1| {4,236E-5} 2,469E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 219: neg. log cond. likelihood = 153.66959360296298 [239 calls to valueAt]\n",
      "Iter 219 evals 238 <D> [M 1,000E0] 1,537E2 22,95s |6,060E-1| {3,845E-5} 2,207E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 220: neg. log cond. likelihood = 153.63810257693592 [240 calls to valueAt]\n",
      "Iter 220 evals 239 <D> [M 1,000E0] 1,536E2 23,03s |4,510E-1| {2,862E-5} 2,175E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 221: neg. log cond. likelihood = 153.6119506368659 [241 calls to valueAt]\n",
      "Iter 221 evals 240 <D> [M 1,000E0] 1,536E2 23,11s |1,029E0| {6,530E-5} 2,101E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 222: neg. log cond. likelihood = 153.57869961533913 [242 calls to valueAt]\n",
      "Iter 222 evals 241 <D> [M 1,000E0] 1,536E2 23,19s |7,625E-1| {4,838E-5} 1,953E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 223: neg. log cond. likelihood = 153.55626507981327 [243 calls to valueAt]\n",
      "Iter 223 evals 242 <D> [M 1,000E0] 1,536E2 23,27s |9,471E-1| {6,010E-5} 1,850E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 224: neg. log cond. likelihood = 153.52441960957344 [244 calls to valueAt]\n",
      "Iter 224 evals 243 <D> [M 1,000E0] 1,535E2 23,35s |8,109E-1| {5,146E-5} 1,900E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 225: neg. log cond. likelihood = 153.4919943064059 [245 calls to valueAt]\n",
      "Iter 225 evals 244 <D> [M 1,000E0] 1,535E2 23,43s |1,067E0| {6,772E-5} 1,862E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 226: neg. log cond. likelihood = 153.4581088822431 [246 calls to valueAt]\n",
      "Iter 226 evals 245 <D> [M 1,000E0] 1,535E2 23,52s |5,961E-1| {3,783E-5} 1,790E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 227: neg. log cond. likelihood = 153.4371278072682 [247 calls to valueAt]\n",
      "Iter 227 evals 246 <D> [M 1,000E0] 1,534E2 23,60s |6,603E-1| {4,190E-5} 1,736E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 228: neg. log cond. likelihood = 153.4161573759883 [248 calls to valueAt]\n",
      "Iter 228 evals 247 <D> [M 1,000E0] 1,534E2 23,68s |5,613E-1| {3,561E-5} 1,652E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 229: neg. log cond. likelihood = 153.39546898743538 [249 calls to valueAt]\n",
      "Iter 229 evals 248 <D> [M 1,000E0] 1,534E2 23,77s |5,401E-1| {3,427E-5} 1,582E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 230: neg. log cond. likelihood = 153.3711059647935 [250 calls to valueAt]\n",
      "Iter 230 evals 249 <D> [M 1,000E0] 1,534E2 23,85s |4,432E-1| {2,813E-5} 1,570E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 231: neg. log cond. likelihood = 153.34678358503973 [251 calls to valueAt]\n",
      "Iter 231 evals 250 <D> [M 1,000E0] 1,533E2 23,93s |9,358E-1| {5,938E-5} 1,512E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 232: neg. log cond. likelihood = 153.31137679471286 [252 calls to valueAt]\n",
      "Iter 232 evals 251 <D> [M 1,000E0] 1,533E2 24,02s |5,897E-1| {3,742E-5} 1,597E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 233: neg. log cond. likelihood = 153.2876888846481 [253 calls to valueAt]\n",
      "Iter 233 evals 252 <D> [M 1,000E0] 1,533E2 24,10s |7,180E-1| {4,556E-5} 1,544E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 234: neg. log cond. likelihood = 153.26205255820986 [254 calls to valueAt]\n",
      "Iter 234 evals 253 <D> [M 1,000E0] 1,533E2 24,18s |9,704E-1| {6,157E-5} 1,500E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 235: neg. log cond. likelihood = 153.24245796487685 [255 calls to valueAt]\n",
      "Iter 235 evals 254 <D> [M 1,000E0] 1,532E2 24,27s |5,349E-1| {3,394E-5} 1,407E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 236: neg. log cond. likelihood = 153.22386224650677 [256 calls to valueAt]\n",
      "Iter 236 evals 255 <D> [M 1,000E0] 1,532E2 24,35s |4,718E-1| {2,994E-5} 1,392E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 237: neg. log cond. likelihood = 153.20229924319588 [257 calls to valueAt]\n",
      "Iter 237 evals 256 <D> [M 1,000E0] 1,532E2 24,43s |7,516E-1| {4,769E-5} 1,396E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 238: neg. log cond. likelihood = 153.18287152476861 [258 calls to valueAt]\n",
      "Iter 238 evals 257 <D> [M 1,000E0] 1,532E2 24,51s |8,083E-1| {5,129E-5} 1,388E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 239: neg. log cond. likelihood = 153.16264841719226 [259 calls to valueAt]\n",
      "Iter 239 evals 258 <D> [M 1,000E0] 1,532E2 24,59s |5,574E-1| {3,537E-5} 1,361E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 240: neg. log cond. likelihood = 153.14910158163252 [260 calls to valueAt]\n",
      "Checking model correctness; x size 34166 , ysize 19\n",
      " Lambda too big 102.14643376010758\n",
      " empirical 2.8714628798162266E-4 expected 2.8714628798162266E-4\n",
      " Lambda too big 102.06382344419364\n",
      " empirical 5.48188367964916E-4 expected 5.48188367964916E-4\n",
      " Lambda too big 136.13414434869665\n",
      " empirical 6.265009919599042E-4 expected 6.265009919599042E-4\n",
      " Lambda too big 103.54595427100767\n",
      " empirical 0.006969823535553943 expected 0.006969823279066579\n",
      " Lambda too big 100.95660609943212\n",
      " empirical 9.397514879398568E-4 expected 9.397514879397748E-4\n",
      " Lambda too big 112.81908465712664\n",
      " empirical 1.8272945598830532E-4 expected 1.8272945598830532E-4\n",
      " Lambda too big 106.42480136869749\n",
      " empirical 5.220841599665867E-4 expected 5.220841599299823E-4\n",
      " Lambda too big 115.36256363921997\n",
      " empirical 6.526051999582336E-4 expected 6.526051999569544E-4\n",
      " Lambda too big 145.43785223621634\n",
      " empirical 7.309178239532217E-4 expected 7.309178239532217E-4\n",
      " Lambda too big 125.33661247125397\n",
      " empirical 2.3493787198496398E-4 expected 2.3493787198496398E-4\n",
      " Lambda too big 134.52619357348118\n",
      " empirical 0.00289756708781456 expected 0.00289757095459752\n",
      " Lambda too big 103.49512393361866\n",
      " empirical 0.0015401482719014324 expected 0.0015401482717792084\n",
      " Lambda too big 118.84698264735427\n",
      " empirical 7.309178239532217E-4 expected 7.309178239532217E-4\n",
      " Lambda too big 144.43696614281495\n",
      " empirical 0.0018011903518847263 expected 0.0018011903518847232\n",
      " Lambda too big 135.5537781392331\n",
      " empirical 4.959799519682573E-4 expected 4.959799516727771E-4\n",
      " Lambda too big 117.93420573277795\n",
      " empirical 3.393547039782813E-4 expected 3.393547039782813E-4\n",
      " Lambda too big 102.7538628906924\n",
      " empirical 3.13250495979952E-4 expected 3.132504959665483E-4\n",
      " Lambda too big 101.34335434451796\n",
      " empirical 0.011146496815286644 expected 0.011145447850639537\n",
      " Lambda too big 107.11950764123686\n",
      " empirical 0.0036023807037694534 expected 0.0036023807037694274\n",
      " Lambda too big 115.24422264475446\n",
      " empirical 0.006186697295604062 expected 0.006186697295604062\n",
      " Lambda too big 109.07525646848507\n",
      " empirical 3.13250495979952E-4 expected 3.1325049597994754E-4\n",
      " Lambda too big 109.45388498503063\n",
      " empirical 0.010337266367338432 expected 0.01033726636733844\n",
      " Lambda too big 107.24966271635454\n",
      " empirical 2.3493787198496398E-4 expected 2.3493787198496398E-4\n",
      " Lambda too big 108.49369852209286\n",
      " empirical 2.8714628798162266E-4 expected 2.8714628796019655E-4\n",
      " Lambda too big 112.41634743167111\n",
      " empirical 0.002140545055863008 expected 0.0021405450548092233\n",
      " Lambda too big 120.51422383363284\n",
      " empirical 9.397514879398568E-4 expected 9.397514879386344E-4\n",
      " Lambda too big 118.9919821397399\n",
      " empirical 0.0012268977759214799 expected 0.0012268977759214799\n",
      " Lambda too big 108.45538114236973\n",
      " empirical 0.0021144408478646786 expected 0.0021144408478646786\n",
      " Lambda too big 103.39904161225158\n",
      " empirical 0.0032630259997911714 expected 0.003263025999791131\n",
      " Lambda too big 109.1266074616015\n",
      " empirical 0.004855382687689262 expected 0.004855382375355537\n",
      " Lambda too big 123.77669014064843\n",
      " empirical 7.831262399498805E-4 expected 7.831262399493656E-4\n",
      " Lambda too big 119.38317303996618\n",
      " empirical 6.78709407956563E-4 expected 6.78709407956563E-4\n",
      " Lambda too big 126.42494672144625\n",
      " empirical 0.008092304479482105 expected 0.008092304479482133\n",
      " Lambda too big 138.48294868538997\n",
      " empirical 3.6545891197661064E-4 expected 3.6545891197661064E-4\n",
      " Lambda too big 135.3765043135224\n",
      " empirical 0.0011485851519264917 expected 0.0011485851519228043\n",
      " Lambda too big 102.86078827132009\n",
      " empirical 0.014670564895061109 expected 0.014670160994889355\n",
      " Lambda too big 130.51990474691934\n",
      " empirical 2.0883366398663465E-4 expected 2.0883366398663465E-4\n",
      " Lambda too big 108.16030443929894\n",
      " empirical 1.8272945598830532E-4 expected 1.827293539724167E-4\n",
      " Lambda too big 113.43037132353783\n",
      " empirical 0.001853398767881385 expected 0.001853398767881385\n",
      " Lambda too big 126.51027827268156\n",
      " empirical 0.025477707006369463 expected 0.02547770700630207\n",
      " Lambda too big 104.10990117934553\n",
      " empirical 2.0883366398663465E-4 expected 2.0883366398663465E-4\n",
      " Lambda too big 115.2668014486673\n",
      " empirical 5.220841599665867E-4 expected 5.220841599665867E-4\n",
      " Lambda too big 122.29618077510804\n",
      " empirical 4.176673279732693E-4 expected 4.1766732797295623E-4\n",
      " Lambda too big 152.34133211392754\n",
      " empirical 6.78709407956563E-4 expected 6.78709407956563E-4\n",
      " Lambda too big 108.00576927509562\n",
      " empirical 9.136472799415274E-4 expected 9.138957169893938E-4\n",
      " Lambda too big 102.95113907337215\n",
      " empirical 2.0883366398663465E-4 expected 2.0883366398662795E-4\n",
      " Lambda too big 118.7874016835914\n",
      " empirical 0.0026626292158295956 expected 0.0026626292158295956\n",
      " Lambda too big 149.39149178281448\n",
      " empirical 0.0408269813093859 expected 0.040826976325873655\n",
      " Lambda too big 150.4977350680482\n",
      " empirical 0.006056176255612415 expected 0.006056176255612415\n",
      " Lambda too big 142.25743370895404\n",
      " empirical 0.006056176255612415 expected 0.006056176108629338\n",
      " Lambda too big 159.59180876267155\n",
      " empirical 0.00206223243186802 expected 0.00206223243186802\n",
      " Lambda too big 146.26150642812755\n",
      " empirical 0.0019578155998747023 expected 0.0019578155998747023\n",
      " Lambda too big 105.78250877357631\n",
      " empirical 0.00415056907173437 expected 0.004150569071733442\n",
      " Lambda too big 182.34918921835512\n",
      " empirical 0.0016967735198914087 expected 0.0016967735198914087\n",
      " Lambda too big 138.18423757669743\n",
      " empirical 0.001514044063903103 expected 0.0015140440638863985\n",
      " Lambda too big 104.1668549345847\n",
      " empirical 3.9156311997493997E-4 expected 3.9156311997493997E-4\n",
      " Lambda too big 137.61939374596173\n",
      " empirical 0.00498590372768091 expected 0.00498590372768091\n",
      " Lambda too big 144.66377400311057\n",
      " empirical 0.002271066095854655 expected 0.002271066095854655\n",
      " Lambda too big 103.63420222876286\n",
      " empirical 0.0010441683199331742 expected 0.0010436765264505733\n",
      " Lambda too big 107.45799849753423\n",
      " empirical 0.0015662524798997618 expected 0.0015662524794967686\n",
      " Lambda too big 163.01206878467465\n",
      " empirical 0.001435731439908115 expected 0.0014357314399076227\n",
      " Lambda too big 127.14708260771886\n",
      " empirical 7.048136159548923E-4 expected 7.048136159548923E-4\n",
      " Lambda too big 104.69454000388632\n",
      " empirical 2.6104207998329333E-4 expected 2.605555393120622E-4\n",
      " Lambda too big 116.7571396345479\n",
      " empirical 0.00498590372768091 expected 0.004985903748086542\n",
      " Lambda too big 110.00086754259401\n",
      " empirical 7.048136159548923E-4 expected 7.048136159548923E-4\n",
      " Lambda too big 105.13367453924624\n",
      " empirical 2.3493787198496398E-4 expected 2.3493787198496398E-4\n",
      " Lambda too big 163.45992312315414\n",
      " empirical 0.01889944659079047 expected 0.018899445931748516\n",
      " Lambda too big 152.56058513693836\n",
      " empirical 0.0018272945598830556 expected 0.0018272945596868925\n",
      " Lambda too big 123.0357284013711\n",
      " empirical 0.0014879398559047737 expected 0.0014879392376180686\n",
      " Lambda too big 109.28777650496923\n",
      " empirical 0.018560091886812187 expected 0.018560091886846472\n",
      " Lambda too big 128.420242701926\n",
      " empirical 6.265009919599042E-4 expected 6.265009735860032E-4\n",
      " Lambda too big 101.3673216655083\n",
      " empirical 0.0011485851519264917 expected 0.0011485851516165977\n",
      " Lambda too big 105.8595424889182\n",
      " empirical 0.0023232745118513137 expected 0.002323274047233496\n",
      " Lambda too big 136.37125220748067\n",
      " empirical 0.0012791061919181386 expected 0.0012791061919181386\n",
      " Lambda too big 113.93601185490328\n",
      " empirical 2.610420799832933E-5 expected 2.6100332622580172E-5\n",
      "Iter 240 evals 259 <D> [M 1,000E0] 1,531E2 24,68s |5,031E-1| {3,192E-5} 1,291E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 241: neg. log cond. likelihood = 153.1335206475993 [261 calls to valueAt]\n",
      "Iter 241 evals 260 <D> [M 1,000E0] 1,531E2 24,77s |3,501E-1| {2,222E-5} 1,161E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 242: neg. log cond. likelihood = 153.1160937989789 [262 calls to valueAt]\n",
      "Iter 242 evals 261 <D> [M 1,000E0] 1,531E2 24,85s |4,733E-1| {3,003E-5} 1,121E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 243: neg. log cond. likelihood = 153.10237991523567 [263 calls to valueAt]\n",
      "Iter 243 evals 262 <D> [M 1,000E0] 1,531E2 24,93s |3,968E-1| {2,518E-5} 1,043E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 244: neg. log cond. likelihood = 153.08825550575276 [264 calls to valueAt]\n",
      "Iter 244 evals 263 <D> [M 1,000E0] 1,531E2 25,01s |3,432E-1| {2,178E-5} 1,007E-4 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 245: neg. log cond. likelihood = 153.0735003659632 [265 calls to valueAt]\n",
      "QNMinimizer terminated due to average improvement: | newest_val - previous_val | / |newestVal| < TOL \n",
      "Total time spent in optimization: 25,09s\n",
      "After optimization neg (penalized) log cond likelihood: 153,07\n",
      "Non-zero parameters: 28553/28553 (100,00%)\n",
      "Checking model correctness; x size 34166 , ysize 19\n",
      " Lambda too big 102.71449114324525\n",
      " empirical 2.8714628798162266E-4 expected 2.8714628798162266E-4\n",
      " Lambda too big 102.61692956857799\n",
      " empirical 5.48188367964916E-4 expected 5.48188367964916E-4\n",
      " Lambda too big 136.8659153939502\n",
      " empirical 6.265009919599042E-4 expected 6.265009919599042E-4\n",
      " Lambda too big 104.07991401884763\n",
      " empirical 0.006969823535553943 expected 0.006969823220657842\n",
      " Lambda too big 101.49497230294426\n",
      " empirical 9.397514879398568E-4 expected 9.397514879397745E-4\n",
      " Lambda too big 113.48154843569053\n",
      " empirical 1.8272945598830532E-4 expected 1.8272945598830532E-4\n",
      " Lambda too big 107.03879956955872\n",
      " empirical 5.220841599665867E-4 expected 5.220841599345733E-4\n",
      " Lambda too big 115.98103633153329\n",
      " empirical 6.526051999582336E-4 expected 6.52605199957029E-4\n",
      " Lambda too big 146.22238244775033\n",
      " empirical 7.309178239532217E-4 expected 7.309178239532217E-4\n",
      " Lambda too big 126.04764098173919\n",
      " empirical 2.3493787198496398E-4 expected 2.3493787198496398E-4\n",
      " Lambda too big 135.2480519546338\n",
      " empirical 0.00289756708781456 expected 0.002897585579923648\n",
      " Lambda too big 104.04749809386627\n",
      " empirical 0.0015401482719014324 expected 0.0015401482717933986\n",
      " Lambda too big 119.48435545456971\n",
      " empirical 7.309178239532217E-4 expected 7.309178239532217E-4\n",
      " Lambda too big 145.1941156626894\n",
      " empirical 0.0018011903518847263 expected 0.0018011903518847232\n",
      " Lambda too big 136.3042022717197\n",
      " empirical 4.959799519682573E-4 expected 4.959799516897051E-4\n",
      " Lambda too big 118.5807443314735\n",
      " empirical 3.393547039782813E-4 expected 3.393547039782813E-4\n",
      " Lambda too big 103.32890202727795\n",
      " empirical 3.13250495979952E-4 expected 3.1325049596743606E-4\n",
      " Lambda too big 101.9188431702029\n",
      " empirical 0.011146496815286644 expected 0.011146598138143185\n",
      " Lambda too big 107.67465751865292\n",
      " empirical 0.0036023807037694534 expected 0.0036023807037694304\n",
      " Lambda too big 115.90861372121563\n",
      " empirical 0.006186697295604062 expected 0.006186697295604062\n",
      " Lambda too big 109.69200928771454\n",
      " empirical 3.13250495979952E-4 expected 3.1325049597994754E-4\n",
      " Lambda too big 110.05818843227726\n",
      " empirical 0.010337266367338432 expected 0.01033726636733844\n",
      " Lambda too big 107.84319021775435\n",
      " empirical 2.3493787198496398E-4 expected 2.3493787198496398E-4\n",
      " Lambda too big 109.10309320219291\n",
      " empirical 2.8714628798162266E-4 expected 2.871462879629524E-4\n",
      " Lambda too big 113.00379542979685\n",
      " empirical 0.002140545055863008 expected 0.0021405450548627695\n",
      " Lambda too big 121.15698040521349\n",
      " empirical 9.397514879398568E-4 expected 9.397514879387038E-4\n",
      " Lambda too big 119.6290137332699\n",
      " empirical 0.0012268977759214799 expected 0.0012268977759214799\n",
      " Lambda too big 109.03398202323119\n",
      " empirical 0.0021144408478646786 expected 0.0021144408478646786\n",
      " Lambda too big 103.9416280498754\n",
      " empirical 0.0032630259997911714 expected 0.0032630259997911337\n",
      " Lambda too big 109.6857445019287\n",
      " empirical 0.004855382687689262 expected 0.0048553823695633245\n",
      " Lambda too big 124.45658103187675\n",
      " empirical 7.831262399498805E-4 expected 7.83126239949333E-4\n",
      " Lambda too big 120.02487154599525\n",
      " empirical 6.78709407956563E-4 expected 6.78709407956563E-4\n",
      " Lambda too big 127.08504569460652\n",
      " empirical 0.008092304479482105 expected 0.008092304479482131\n",
      " Lambda too big 139.23858231009865\n",
      " empirical 3.6545891197661064E-4 expected 3.6545891197661064E-4\n",
      " Lambda too big 136.10893818536178\n",
      " empirical 0.0011485851519264917 expected 0.0011485851519229995\n",
      " Lambda too big 103.40135215429022\n",
      " empirical 0.014670564895061109 expected 0.01467052700959015\n",
      " Lambda too big 131.24614175955585\n",
      " empirical 2.0883366398663465E-4 expected 2.0883366398663465E-4\n",
      " Lambda too big 108.7727665580398\n",
      " empirical 1.8272945598830532E-4 expected 1.8272935647098345E-4\n",
      " Lambda too big 114.03306357681717\n",
      " empirical 0.001853398767881385 expected 0.001853398767881385\n",
      " Lambda too big 127.20028595131195\n",
      " empirical 0.025477707006369463 expected 0.025477707006305327\n",
      " Lambda too big 104.69373045854205\n",
      " empirical 2.0883366398663465E-4 expected 2.0883366398663465E-4\n",
      " Lambda too big 115.89032590179251\n",
      " empirical 5.220841599665867E-4 expected 5.220841599665867E-4\n",
      " Lambda too big 122.95884986962547\n",
      " empirical 4.176673279732693E-4 expected 4.1766732797298735E-4\n",
      " Lambda too big 153.1614891353603\n",
      " empirical 6.78709407956563E-4 expected 6.78709407956563E-4\n",
      " Lambda too big 108.42572225029161\n",
      " empirical 9.136472799415274E-4 expected 9.136359933622293E-4\n",
      " Lambda too big 103.56456367263864\n",
      " empirical 2.0883366398663465E-4 expected 2.0883366398662944E-4\n",
      " Lambda too big 119.41106013488015\n",
      " empirical 0.0026626292158295956 expected 0.0026626292158295956\n",
      " Lambda too big 150.22621318124422\n",
      " empirical 0.0408269813093859 expected 0.04082697679208764\n",
      " Lambda too big 151.2742496675444\n",
      " empirical 0.006056176255612415 expected 0.006056176255612415\n",
      " Lambda too big 142.9983176877114\n",
      " empirical 0.006056176255612415 expected 0.006056176103184515\n",
      " Lambda too big 160.43274102632714\n",
      " empirical 0.00206223243186802 expected 0.00206223243186802\n",
      " Lambda too big 147.03215529468633\n",
      " empirical 0.0019578155998747023 expected 0.0019578155998747023\n",
      " Lambda too big 106.33422947998287\n",
      " empirical 0.00415056907173437 expected 0.004150569071733496\n",
      " Lambda too big 183.31261457963515\n",
      " empirical 0.0016967735198914087 expected 0.0016967735198914087\n",
      " Lambda too big 138.91890308605394\n",
      " empirical 0.001514044063903103 expected 0.00151404406388683\n",
      " Lambda too big 104.73062250054895\n",
      " empirical 3.9156311997493997E-4 expected 3.9156311997493997E-4\n",
      " Lambda too big 138.32468573169416\n",
      " empirical 0.00498590372768091 expected 0.00498590372768091\n",
      " Lambda too big 145.44225208967612\n",
      " empirical 0.002271066095854655 expected 0.002271066095854655\n",
      " Lambda too big 104.20612512551905\n",
      " empirical 0.0010441683199331742 expected 0.0010445479404881917\n",
      " Lambda too big 108.04918763803599\n",
      " empirical 0.0015662524798997618 expected 0.0015662524794992705\n",
      " Lambda too big 163.87880425801254\n",
      " empirical 0.001435731439908115 expected 0.0014357314399076797\n",
      " Lambda too big 127.83182581034208\n",
      " empirical 7.048136159548923E-4 expected 7.048136159548923E-4\n",
      " Lambda too big 105.20807112947962\n",
      " empirical 2.6104207998329333E-4 expected 2.612634100326719E-4\n",
      " Lambda too big 117.41392147139757\n",
      " empirical 0.00498590372768091 expected 0.004985903747975344\n",
      " Lambda too big 110.5896824180471\n",
      " empirical 7.048136159548923E-4 expected 7.048136159548923E-4\n",
      " Lambda too big 105.71711381546267\n",
      " empirical 2.3493787198496398E-4 expected 2.3493787198496398E-4\n",
      " Lambda too big 164.40897139264936\n",
      " empirical 0.01889944659079047 expected 0.0188994460007324\n",
      " Lambda too big 153.37774465492402\n",
      " empirical 0.0018272945598830556 expected 0.0018272945596921348\n",
      " Lambda too big 123.7218209480212\n",
      " empirical 0.0014879398559047737 expected 0.0014879392719562797\n",
      " Lambda too big 109.89771053966204\n",
      " empirical 0.018560091886812187 expected 0.01856009188683931\n",
      " Lambda too big 129.11726951904492\n",
      " empirical 6.265009919599042E-4 expected 6.265009742356136E-4\n",
      " Lambda too big 101.91016467716837\n",
      " empirical 0.0011485851519264917 expected 0.0011485851516274627\n",
      " Lambda too big 106.43717996232166\n",
      " empirical 0.0023232745118513137 expected 0.002323274017581459\n",
      " Lambda too big 137.09201127139244\n",
      " empirical 0.0012791061919181386 expected 0.0012791061919181386\n",
      " Lambda too big 114.64332692423734\n",
      " empirical 2.610420799832933E-5 expected 2.6100605477372508E-5\n",
      "Model is correct [empirical expec = model expec]\n",
      "Saving dictionary of 9275 words ...\n",
      "Extractors list:\n",
      "Extractors[Extractor(-1,word), Extractor(0,word), Extractor(1,word), ExtractorFrames$ExtractorContinuousTagConjunction(-2,tag), Extractor(-1,tag)]\n",
      "rareExtractors[ExtractorUCase(), ExtractorCNumber(), ExtractorDash(), ExtractorAllCap(), ExtractorLetterDigitDash(), CompanyNameDetector(), ExtractorAllCapitalized(), ExtractorUpperDigitDash(), ExtractorStartSentenceCap(), ExtractorMidSentenceCapC(), ExtractorMidSentenceCap(), ExtractorWordSuff(len1,w0), ExtractorWordSuff(len2,w0), ExtractorWordSuff(len3,w0), ExtractorWordSuff(len4,w0), ExtractorWordSuff(len5,w0), ExtractorWordSuff(len6,w0), ExtractorWordSuff(len7,w0), ExtractorWordSuff(len8,w0), ExtractorWordSuff(len9,w0), ExtractorWordSuff(len10,w0), ExtractorWordPref(len1,w0), ExtractorWordPref(len2,w0), ExtractorWordPref(len3,w0), ExtractorWordPref(len4,w0), ExtractorWordPref(len5,w0), ExtractorWordPref(len6,w0), ExtractorWordPref(len7,w0), ExtractorWordPref(len8,w0), ExtractorWordPref(len9,w0), ExtractorWordPref(len10,w0), ExtractorWordShapeClassifier(-1,chris4), ExtractorWordShapeClassifier(0,chris4), ExtractorWordShapeClassifier(1,chris4)]\n",
      "Training POS tagger done [29.5 sec].\n"
     ]
    }
   ],
   "source": [
    "!java -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger \\\n",
    "  -props 'myFrench-ud.tagger.props' \\\n",
    "  -trainFile 'format=TSV,wordColumn=1,tagColumn=3,fr-ud-dev.conllu3' \\\n",
    "  -verboseResults false \\\n",
    "  -iterations 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default properties from tagger myFrench-ud.tagger\n",
      "Loading POS tagger from myFrench-ud.tagger ... done [0.0 sec].\n",
      "Tagged 10298 words at 26070,89 words per second.\n",
      "Model myFrench-ud.tagger has xSize=34166, ySize=19, and numFeatures=28553.\n",
      "Results on 416 sentences and 10298 words, of which 1687 were unknown.\n",
      "Total sentences right: 126 (30,288462%); wrong: 290 (69,711538%).\n",
      "Total tags right: 9579 (93,018062%); wrong: 719 (6,981938%).\n",
      "Unknown words right: 1370 (81,209247%); wrong: 317 (18,790753%).\n"
     ]
    }
   ],
   "source": [
    "!java -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger \\\n",
    "  -model 'myFrench-ud.tagger' \\\n",
    "  -testFile 'format=TSV,wordColumn=1,tagColumn=3,fr-ud-test.conllu3' \\\n",
    "  -verboseResults false\n",
    "\n",
    "# Pour comparer, nous remettons les précisions du tagger de Stanford:\n",
    "#   Phrases: ~12.98%\n",
    "#   Tokens: ~87.01%\n",
    "#   Mots inconnus: ~69.87%\n",
    "\n",
    "# Results on 416 sentences and 10298 words, of which 1687 were unknown.\n",
    "# Total sentences right: 126 (30,288462%); wrong: 290 (69,711538%).\n",
    "# Total tags right: 9579 (93,018062%); wrong: 719 (6,981938%).\n",
    "# Unknown words right: 1370 (81,209247%); wrong: 317 (18,790753%)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quel modèle est meilleur, le vôtre ou celui fourni par Stanford ? Formulez une hypothèse expliquant ce résultat.\n",
    "\n",
    "#### Précisions du tagger de Stanford sur le fichier fr-ud-test.conllu3:\n",
    "* Phrases: ~12.98%\n",
    "* Tokens: ~87.01%\n",
    "* Mots inconnus: ~69.87%\n",
    "\n",
    "#### Précisions du tagger de notre modèle sur le fichier fr-ud-test.conllu3:\n",
    "TODO mettre les valeurs du run de vali\n",
    "* Phrases: ~39,90%\n",
    "* Tokens: 95,39%\n",
    "* Mots inconnus: ~82,70%\n",
    "\n",
    "Notre modèle a donc des valeurs bie meilleures que celui de Stanford. En effet, notre modèle atteint les 95% de précision sur les tokens. Mais la partie la plus impressionnante est le nombre de phrases correctement taggées. En effet, notre modèle tagge 39,90% des phrases correctement alors que Stanford n'en tagge que 12,98%. C'est environ 3 fois plus.\n",
    "\n",
    "Nous pouvons expliquer ce résultat sur le fait que nous réalisons un nombre d'itérations plus important que celui fourni par Stanford (500 vs 100). De plus, les modifications sur les rares words doivent avoir un impact bénéfique sur nos résultats. \n",
    "\n",
    "Nous pouvons également supposer que le modèle fournit par stanford est prévu pour des textes en anglais et marche donc moins bien sur des données en français."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3 : entraîner un POS tagger pour le français dans NLTK\n",
    "\n",
    "Le but de cette partie est d'utiliser le POS tagger *Averaged Perceptron* de NLTK, en l'entraînant pour le français sur les mêmes données que ci-dessus.  \n",
    "\n",
    "Notez que pour l'anglais, des taggers pré-entraînés sont disponibles dans NLTK, comme expliqué au [Chapitre 5.1 du livre NLTK](http://www.nltk.org/book/ch05.html) : on peut écrire `nltk.pos_tag(sentence)` où *sentence* est une phrase tokenisée. L'étiquetage morpho-syntaxique produira des paires ('mot', 'TAG').\n",
    "\n",
    "**Première étape**\n",
    "\n",
    "Importer les textes annotés `fr-ud-XXXX.conllu3` grâce à des objets `ConllCorpusReader`.  Consultez le mode d'emploi de cette classe directement dans [son code source](https://www.nltk.org/_modules/nltk/corpus/reader/conll.html#ConllCorpusReader), pour déterminer comment lire un fichier en créant un objet `ConllCorpusReader`.  Chargez les trois fichiers, dans trois objets appelés `train_corpus`, `dev_corpus` et `test_corpus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.conll import ConllCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Les', 'DET'), ('commotions', 'NOUN'), ...]\n",
      "[('Aviator', 'PROPN'), (',', 'PUNCT'), ('un', 'DET'), ...]\n",
      "[('Je', 'PRON'), ('sens', 'VERB'), (\"qu'\", 'SCONJ'), ...]\n"
     ]
    }
   ],
   "source": [
    "def get_corpus(file):\n",
    "    return ConllCorpusReader(\n",
    "        \".\", \n",
    "        file, \n",
    "        ('ignore', 'words', 'ignore', 'pos'),\n",
    "        separator=\"\\t\"\n",
    "    )\n",
    "\n",
    "train_corpus = get_corpus(\"fr-ud-train.conllu3\")\n",
    "dev_corpus = get_corpus(\"fr-ud-dev.conllu3\")\n",
    "test_corpus = get_corpus(\"fr-ud-test.conllu3\")\n",
    "\n",
    "print(train_corpus.tagged_words())\n",
    "print(dev_corpus.tagged_words())\n",
    "print(test_corpus.tagged_words())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez le nombre de phrases et le nombre de mots de chaque corpus chargé. Ces chiffres sont-ils identiques à ceux obtenus pour `dev` et pour `test` à la fin de la Partie 1 ? On peut obtenir les listes de mots étiquetés avec `tagged_words()` et les listes de phrases avec mots étiquetés avec `tagged_sents()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -------------\n",
      "Nombre de mots: 366371\n",
      "Nombre de phrases: 14554\n",
      "\n",
      "Dev -------------\n",
      "Nombre de mots: 36830\n",
      "Nombre de phrases: 1478\n",
      "\n",
      "Test -------------\n",
      "Nombre de mots: 10298\n",
      "Nombre de phrases: 416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_corpus = [(\"Train\", train_corpus), (\"Dev\", dev_corpus), (\"Test\", test_corpus)]\n",
    "\n",
    "for corpus in all_corpus:\n",
    "    print(f\"{corpus[0]} -------------\")\n",
    "    print(f\"Nombre de mots: {len(corpus[1].tagged_words())}\")\n",
    "    print(f\"Nombre de phrases: {len(corpus[1].tagged_sents())}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison avec les résultats de la fin de la partie 1\n",
    "\n",
    "**Dev:** Le tagger trouve 36830 mots et 1478 phrases. \n",
    "\n",
    "**Test:** Le tagger trouve 10298 mots et 416 phrases. \n",
    "\n",
    "Les résultats sont donc les mêmes pour les deux corpus avec la partie 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez la 17e phrase du corpus de développement (avec les étiquettes POS), et les mots 1001 à 1050 du corpus de test (aussi avec leurs POS tags)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17e phrase\n",
      "[('Comprenant', 'VERB'), ('six', 'NUM'), ('sommets', 'NOUN'), ('dont', 'PRON'), ('un', 'DET'), ('point', 'NOUN'), ('culminant', 'VERB'), ('à', 'ADP'), ('2 001', 'NUM'), ('mètres', 'NOUN'), ('et', 'CCONJ'), ('une', 'DET'), ('arrivée', 'NOUN'), ('en', 'ADP'), ('altitude', 'NOUN'), (',', 'PUNCT'), (\"c'\", 'PRON'), ('est', 'AUX'), ('une', 'DET'), ('étape', 'NOUN'), ('typique', 'ADJ'), ('de', 'ADP'), ('montagne', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Mots 1001 -> 1050\n",
      "[('dans', 'ADP'), ('la', 'DET'), ('raison', 'NOUN'), ('politique', 'ADJ'), ('...', 'PUNCT'), ('Mais', 'CCONJ'), ('la', 'DET'), ('réalité', 'NOUN'), ('est', 'VERB'), ('que', 'SCONJ'), ('la', 'DET'), ('Mauritanie', 'PROPN'), (\"n'\", 'ADV'), ('est', 'AUX'), ('pas', 'ADV'), ('le', 'DET'), ('Maroc', 'PROPN'), ('ou', 'CCONJ'), (\"l'\", 'DET'), ('Algérie', 'PROPN'), ('.', 'PUNCT'), ('En', 'ADP'), ('Arabie', 'PROPN'), (',', 'PUNCT'), ('on', 'PRON'), ('a', 'VERB'), (\"l'\", 'DET'), ('impression', 'NOUN'), ('que', 'SCONJ'), ('le', 'DET'), ('fondamentalisme', 'NOUN'), ('a', 'AUX'), ('toujours', 'ADV'), ('été', 'VERB'), ('là', 'ADV'), (',', 'PUNCT'), (\"qu'\", 'SCONJ'), ('il', 'PRON'), ('se', 'PRON'), ('maintient', 'VERB'), ('et', 'CCONJ'), (\"n'\", 'ADV'), ('aura', 'VERB'), ('aucun', 'DET'), ('mal', 'NOUN'), ('à', 'ADP'), ('perdurer', 'VERB'), ('.', 'PUNCT'), ('Y', 'PRON')]\n"
     ]
    }
   ],
   "source": [
    "print(\"17e phrase\")\n",
    "print(f\"{dev_corpus.tagged_sents()[16]}\\n\")\n",
    "\n",
    "print(\"Mots 1001 -> 1050\")\n",
    "print(test_corpus.tagged_words()[1000:1049])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seconde étape**\n",
    "\n",
    "Vous allez maintenant entraîner (sur le corpus `train`) le POS tagger appelé *Averaged Perceptron* fourni par NLTK mais [implémenté par Mathew Honnibal de Explosion.AI](https://explosion.ai/blog/part-of-speech-pos-tagger-in-python).\n",
    "\n",
    "Dans le [package de NLTK avec des taggers](http://www.nltk.org/api/nltk.tag.html), considérez le module `nltk.tag.perceptron`, pour lequel NLTK explique de façon précise l'entraînement (voir *train the model*) et le test.  Vous allez mettre en oeuvre ces étapes pour entraîner le tagger.  Notez que le modèle est enregistré dans un fichier qui doit finir par `.pickle`, et qui est écrasé à chaque entraînement si vous ne changez pas de nom.  Un modèle peut être également chargé dans un tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os # si nécessaire\n",
    "# import nltk # si nécessaire\n",
    "# nltk.download('averaged_perceptron_tagger') # si nécessaire\n",
    "from nltk.tag.perceptron import PerceptronTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptagger = PerceptronTagger(load=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînez ici le tagger sur les données d'entraînement, avec les meilleurs paramètres possibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début de l'entraînement...\n",
      "Temps d'entraînement: 48.3787 secondes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"Début de l'entraînement...\")\n",
    "ptagger.train(\n",
    "    train_corpus.tagged_sents(),\n",
    "    save_loc=\"training_model.pickle\",\n",
    "    nr_iter=10\n",
    ")\n",
    "print(f\"Temps d'entraînement: {round((time.time() - start_time), 4)} secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combien de temps prend l'entraînement ?  Quelle est la taille du fichier modèle résultant ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'entraînement prend environ **48.4 secondes** pour 10 itérations.\n",
    "\n",
    "La taille du fichier modèle est de **8.4 Mo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Évaluez le tagger, d'abord sur les données `dev` puis sur les données `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9671191963073581\n",
      "0.9597980190328219\n"
     ]
    }
   ],
   "source": [
    "print(ptagger.accuracy(dev_corpus.tagged_sents()))\n",
    "print(ptagger.accuracy(test_corpus.tagged_sents()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veuillez remplir le tableau suivant avec la synthèse des résultats.\n",
    "\n",
    "| Corpus | MaxEnt | MaxEnt   | Avg Perceptron | \n",
    "|--------|--------|----------|---------------|\n",
    "| -      | fourni | entraîné | entraîné |\n",
    "| dev    |   0.8786   |   ..     |  0.9671  |\n",
    "| test   |   0.8701   |   ..     |  0.9598  |\n",
    "\n",
    "Comment se comparent les deux POS taggers sur le français ?  Écrivez vos conclusions dans cette cellule.\n",
    "\n",
    "TODO\n",
    "\n",
    "Avantager partie 3: temps d'exécution  \n",
    "Désavantage partie 3: taille du fichier modèle (8.4 Mo vs 1.1 Mo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin du laboratoire 2  \n",
    "\n",
    "Merci de nettoyer votre feuille, exécuter une dernière fois toutes les instructions, sauvegarder le résultat, et le rendre via Cyberlearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
