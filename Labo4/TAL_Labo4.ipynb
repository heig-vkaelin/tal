{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tester et évaluer un modèle entraîné sur Google News"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **a.** \n",
    "\n",
    "Installez gensim, une librairie Python qui fournit des outils pour travailler avec Word2Vec (avec conda ou avec pip).**\n",
    "\n",
    "Prenez la version 3.8.3, et non pas la nouvelle version 4.0.X. Obtenez depuis gensim le modèle word2vec pré-entraîné sur le corpus Google News en écrivant : \n",
    "```python \n",
    "w2v_model = gensim.downloader.load(\"word2vec-google-news-300\")\n",
    "```\n",
    "Ce qui téléchargera le fichier la première fois. Ne gardez en mémoire que les vecteurs des mots, en écrivant :  \n",
    "\n",
    "```python \n",
    "w2v_vectors = w2v_model.wv\n",
    "# puis\n",
    "del w2v_model\n",
    "``` \n",
    "• Une fois que vous avez téléchargé le modèle, vous pouvez utiliser votre copie locale :\n",
    "```python \n",
    "w2v_vectors = KeyedVectors.load_word2vec_format(path_to_file, binary=True)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/lazar/.pyenv/versions/3.11.2/envs/tal/lib/python3.11/site-packages (4.3.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/lazar/.pyenv/versions/3.11.2/envs/tal/lib/python3.11/site-packages (from gensim) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/lazar/.pyenv/versions/3.11.2/envs/tal/lib/python3.11/site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/lazar/.pyenv/versions/3.11.2/envs/tal/lib/python3.11/site-packages (from gensim) (6.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import downloader, models\n",
    "# downloader.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "path_to_file = \"~/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\"\n",
    "w2v_vectors = KeyedVectors.load_word2vec_format(path_to_file, binary=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **b.** \n",
    "Quelle place mémoire occupe le processus du notebook une fois les vecteurs de mots chargés ?\n",
    "\n",
    "Le processus python du notebook occupe **3.92 GB** de mémoire une fois les vecteurs de mots chargés."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **c.** \n",
    "\n",
    "Quelle est la dimension de l’espace vectoriel dans lequel les mots sont représentés ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de dimensions: 300\n"
     ]
    }
   ],
   "source": [
    "size_vocab, nb_dimension = w2v_vectors.vectors.shape\n",
    "\n",
    "print(f'Nombre de dimensions: {nb_dimension}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **d.**\n",
    "\n",
    "Quelle est la taille du vocabulaire du modèle ? Affichez cinq mots (anglais) qui sont dans le vocabulaire et deux qui ne le sont pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire : 3000000\n",
      "hello : True\n",
      "world : True\n",
      "apple : True\n",
      "dog : True\n",
      "cat : True\n",
      "cryptocurrency : False\n",
      "deepfake : False\n"
     ]
    }
   ],
   "source": [
    "# d. Quelle est la taille du vocabulaire du modèle ? Affichez cinq mots (anglais) qui sont dans le vocabulaire et deux qui ne le sont pas.\n",
    "\n",
    "print(f'Taille du vocabulaire : {size_vocab}')\n",
    "\n",
    "words = ['hello', 'world', 'apple', 'dog', 'cat', 'cryptocurrency', 'deepfake']\n",
    "for word in words:\n",
    "    print(f'{word} : {word in w2v_vectors.key_to_index}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **e.** \n",
    "\n",
    "Quelle est la distance entre les mots rabbit et carrot ? Veuillez aussi expliquer en une phrase comment on mesurer les distances entre deux mots dans cet espace."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La distance entre deux mots est mesurée en utilisant la similarité cosinus. En effet, la distance correspond à 1 - la similarité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance entre rabbit et carrot : 0.6369356513023376\n"
     ]
    }
   ],
   "source": [
    "rabbit_carrot_dist = w2v_vectors.distance('rabbit', 'carrot')\n",
    "\n",
    "print(f'Distance entre rabbit et carrot : {rabbit_carrot_dist}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **f.** \n",
    "Considérez au moins 5 paires de mots, certains proches par leurs sens, d’autres plus éloignés. Pour chaque paire, calculez la distance entre les deux mots. Veuillez indiquer si les distances obtenues correspondent à vos intuitions sur la proximité des sens des mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance entre festival et watch : 0.9337479248642921\n",
      "Distance entre confident et cocky : 0.6400514245033264\n",
      "Distance entre tree et leaf : 0.5177146792411804\n",
      "Distance entre meticulous et nitpicky : 0.7041851878166199\n",
      "Distance entre dog et car : 0.68999844789505\n"
     ]
    }
   ],
   "source": [
    "word_pairs = [('festival', 'watch'), ('confident', 'cocky'), ('tree', 'leaf'), ('meticulous', 'nitpicky'), ('dog', 'car')]\n",
    "for pair in word_pairs:\n",
    "    print(f'Distance entre {pair[0]} et {pair[1]} : {w2v_vectors.distance(pair[0], pair[1])}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certaines paires obtiennent des distances qui correspondent à nos intuitions, d'autres non. Par exemple, les paires (festival, watch) et (dog, car) ont une distance élevée car les mots n'ont pas de sens proche. \n",
    "\n",
    "Par contre, d'autres paires comme (tree, leaf), (confident, cocky) ou (meticulous, nitpicky) ont une distance plus élevée que ce que nous aurions pensé."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **g.** \n",
    "\n",
    "Pouvez-vous trouver des mots de sens opposés mais qui sont proches dans l’espace vectoriel ? Comment expliquez vous cela ? Est-ce une qualité ou un défaut du modèle word2vec ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance entre good et bad : 0.28099489212036133\n",
      "Distance entre up et down : 0.36030077934265137\n",
      "Distance entre black et white : 0.19077849388122559\n"
     ]
    }
   ],
   "source": [
    "opposite_pairs = [('good', 'bad'), ('up', 'down'), ('black', 'white')]\n",
    "\n",
    "for pair in opposite_pairs:\n",
    "    print(f'Distance entre {pair[0]} et {pair[1]} : {w2v_vectors.distance(pair[0], pair[1])}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela est dû au fait que les mots peuvent être utilisés dans le même contexte et possèdent un lien sémantique. Il s'agit d'une qualité du modèle car il arrive alors à faire des rapprochements plus subtiles que simplement trouver des similarités entre synonymes par exemple."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **h.** \n",
    "\n",
    "En vous aidant de la documentation de Gensim sur KeyedVectors, calculez le score du modèle word2vec sur les données WordSimilarity-353. (La doc vous permettra aussi de récupérer le fichier.)  \n",
    "\n",
    "Expliquez en 1-2 phrases comment ce score est calculé et ce qu’il mesure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wordsim353:\n",
      "(PearsonRResult(statistic=0.6238773487289394, pvalue=1.7963224351224885e-39), SignificanceResult(statistic=0.6589215888009288, pvalue=2.534605645914962e-45), 0.0)\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "eval_wordsim = w2v_vectors.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
    "print(\"Wordsim353:\")\n",
    "print(eval_wordsim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode `evaluate_word_pairs()` compare la similarité cosinus entre les vecteurs de mots du modèle avec les scores de similarité humaine fournis dans le fichier `wordsim353.tsv`. Le score mesuré est la corrélation de Spearman entre ces deux ensembles de scores de similarité, et il indique dans quelle mesure le modèle est capable de reproduire les jugements de similarité humaine sur ces paires de mots spécifiques."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **i.** \n",
    "\n",
    "En vous aidant de la documentation, calculez le score du modèle word2vec sur les données `questions-words.txt`. Attention, cette évaluation prend une dizaine de minutes. Expliquez en 1-2 phrases comment ce score est calculé et ce qu’il mesure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_qwords = w2v_vectors.evaluate_word_analogies(\n",
    "    datapath('questions-words.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions Words:\n",
      "Score: 0.7401448525607863\n"
     ]
    }
   ],
   "source": [
    "print(\"Questions Words:\")\n",
    "print(f\"Score: {eval_qwords[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode `evaluate_word_analogies()` évalue la performance du modèle sur des tâches d'analogie de mots, où il doit trouver un mot D qui complète l'analogie A est à B comme C est à D. Le score mesuré est la proportion de bonnes réponses parmi toutes les analogies testées, indiquant la capacité du modèle à résoudre correctement ces analogies en utilisant ses représentations vectorielles de mots."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Entraîner deux nouveaux modèles word2vec à partir de nouveaux corpus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **a.** \n",
    "\n",
    "En utilisant gensim.downloader, récupérez le corpus qui contient les 108 premiers caractères de Wikipédia (en anglais) avec la commande :**\n",
    "```python\n",
    "corpus = gensim.downloader.load('text8')\n",
    "```\n",
    "\n",
    "Combien de phrases et de mots (tokens) possède ce corpus ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences 1701\n",
      "Number of words:  17005207\n"
     ]
    }
   ],
   "source": [
    "corpus = downloader.load('text8')\n",
    "\n",
    "print(\"Number of sentences\", downloader.info('text8')['num_records'])\n",
    "print(\"Number of words: \", sum(len(i) for i in corpus))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **b.** \n",
    "\n",
    "Entraînez un nouveau modèle word2vec sur ce nouveau corpus. Si nécessaire, procédez progressivement, en commençant par 1% du corpus, puis 10%, pour contrôler le temps nécessaire. \n",
    "\n",
    "• Indiquez la dimension choisie pour le embedding de ce nouveau modèle.  \n",
    "• Combien de temps prend l’entraînement sur le corpus total ?  \n",
    "• Quelle est la taille (en Mo) du modèle word2vec résultant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'entrainement sur 1% du corpus : 0.2372300624847412\n",
      "Temps d'entrainement sur 10% du corpus : 2.9472970962524414\n",
      "Temps d'entrainement sur 100% du corpus : 36.639487981796265\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "corpus_1 = [sentence[:len(sentence)//100] for sentence in corpus]\n",
    "corpus_10 = [sentence[:len(sentence)//10] for sentence in corpus]\n",
    "\n",
    "# 1% du corpus\n",
    "start_time = time.time()\n",
    "model_1 = Word2Vec(corpus_1)\n",
    "print(f\"Temps d'entrainement sur 1% du corpus : {time.time() - start_time}\")\n",
    "\n",
    "# 10% du corpus\n",
    "start_time = time.time()\n",
    "model_10 = Word2Vec(corpus_10)\n",
    "print(f\"Temps d'entrainement sur 10% du corpus : {time.time() - start_time}\")\n",
    "\n",
    "# 100% du corpus\n",
    "start_time = time.time()\n",
    "model_100 = Word2Vec(corpus)\n",
    "print(f\"Temps d'entrainement sur 100% du corpus : {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du modèle sur 1% du corpus : 5.4054 Mo, Dimension des embeddings: 100\n",
      "Taille du modèle sur 10% du corpus : 25.9779 Mo, Dimension des embeddings: 100\n",
      "Taille du modèle sur 100% du corpus : 92.677 Mo, Dimension des embeddings: 100\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Taille du modèle sur 1% du corpus : {model_1.estimate_memory()['total'] / 1000000} Mo, Dimension des embeddings: {model_1.vector_size}\")\n",
    "print(\n",
    "    f\"Taille du modèle sur 10% du corpus : {model_10.estimate_memory()['total'] / 1000000} Mo, Dimension des embeddings: {model_10.vector_size}\")\n",
    "print(\n",
    "    f\"Taille du modèle sur 100% du corpus : {model_100.estimate_memory()['total'] / 1000000} Mo, Dimension des embeddings: {model_100.vector_size}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **c.** \n",
    "\n",
    "Mesurez la qualité de ce modèle comme dans la partie 1, points i et j. Ce modèle est-il meilleur que celui entraîné sur Google News ? Quelle serait la raison de la différence ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_qwords_text8 = model_100.wv.evaluate_word_analogies(datapath('questions-words.txt'))\n",
    "eval_wordsim_text8 = model_100.wv.evaluate_word_pairs(datapath('wordsim353.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wordsim353:\n",
      "Google News:  PearsonRResult(statistic=0.6238773487289394, pvalue=1.7963224351224885e-39)\n",
      "Text8:  PearsonRResult(statistic=0.6191131746160552, pvalue=1.6004556742509145e-38)\n",
      "\n",
      "Questions Words:\n",
      "Google News:\t 0.7401448525607863\n",
      "Text8:\t\t 0.23621473046502497\n"
     ]
    }
   ],
   "source": [
    "print(\"Wordsim353:\")\n",
    "print(\"Google News: \", eval_wordsim[0])\n",
    "print(\"Text8: \", eval_wordsim_text8[0])\n",
    "\n",
    "print(\"\\nQuestions Words:\")\n",
    "print(\"Google News:\\t\", eval_qwords[0])\n",
    "print(\"Text8:\\t\\t\", eval_qwords_text8[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tokens dans le modèle Google News (dimension de 300):\t 3000000\n",
      "Nombre de tokens dans le modèle Text8 (dimension de 100):\t 71290\n"
     ]
    }
   ],
   "source": [
    "# Différences entre les modèles\n",
    "w2v_vec_tokens, w2v_vec_dim = w2v_vectors.vectors.shape\n",
    "model_100_tokens, model_100_dim = model_100.wv.vectors.shape\n",
    "\n",
    "print(f'Nombre de tokens dans le modèle Google News (dimension de {w2v_vec_dim}):\\t {w2v_vec_tokens}')\n",
    "print(f'Nombre de tokens dans le modèle Text8 (dimension de {model_100_dim}):\\t {model_100_tokens}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle Google News est bien plus performant que notre modèle entraîné sur le corpus Text8. On observe que son score de similarité est trois fois plus élevé que celui de Text8 lors de l'évaluation `Questions Words`. Pour l'évaluation `Wordsim353`, elle est légèrement plus élevée avec une pvalue également plus petite, indiquant une probabilité moins élevée que ce soit le fruit du hasard.\n",
    "\n",
    "Nous supposons que la taille du corpus de Google News est bien supérieure à celle de Text8 culminant à environ 17 millions de mots. De plus, nous savons que la taille du vocabulaire du modèle Google News est de 3 millions de mots, contre 71'290 pour Text8, soit 42x fois plus grande. Il est donc normal que le modèle Google News soit plus performant que le modèle Text8."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **d.** \n",
    "\n",
    "Téléchargez maintenant le corpus quatre fois plus grand constitué de la concaténation du corpus text8 et des dépêches économiques de Reuters (413 Mo) fourni en ligne par l’enseignant et appelé wikipedia_augmented.dat. Entraînez un nouveau modèle word2vec sur ce corpus, en précisant la dimension du plongement (embedding).\n",
    "\n",
    "\n",
    "• Utilisez la classe `Text8Corpus()` pour charger le corpus et faire la tokenization et la segmentation en phrases.  \n",
    "• Combien de temps prend l’entraînement ?  \n",
    "• Quelle est la taille (en Mo) du modèle word2vec résultant ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Text8Corpus\n",
    "\n",
    "corpus_augmented = Text8Corpus('wikipedia_augmented.dat')\n",
    "\n",
    "# model_augmented = models.Word2Vec(corpus_augmented)\n",
    "# model_augmented.save(\"wiki_augmented.model\")\n",
    "\n",
    "# model_augmented_300 = models.Word2Vec(corpus_augmented, vector_size=300)\n",
    "# model_augmented_300.save(\"wiki_augmented_300.model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temps d'entraînement avec une dimension de 300 : 4m 17s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_augmented = models.Word2Vec.load(\"wiki_augmented.model\")\n",
    "model_augmented_300 = models.Word2Vec.load(\"wiki_augmented_300.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du modèle augmenté : 161.6836 Mo, Dimension des embeddings: 100\n",
      "Taille du modèle augmenté de dimension 300 : 360.6788 Mo, Dimension des embeddings: 300\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Taille du modèle augmenté : {model_augmented.estimate_memory()['total'] / 1000000} Mo, Dimension des embeddings: {model_augmented.vector_size}\")\n",
    "\n",
    "print(\n",
    "    f\"Taille du modèle augmenté de dimension 300 : {model_augmented_300.estimate_memory()['total'] / 1000000} Mo, Dimension des embeddings: {model_augmented_300.vector_size}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **e.** \n",
    "\n",
    "Testez ce modèle comme en 1.h et 1.i. Est-il meilleur que le précédent ? Pour quelle raison ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_qwords_text8_augmented = model_augmented.wv.evaluate_word_analogies(datapath('questions-words.txt'))\n",
    "eval_wordsim_text8_augmented = model_augmented.wv.evaluate_word_pairs(datapath('wordsim353.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_qwords_text8_augmented_300 = model_augmented_300.wv.evaluate_word_analogies(\n",
    "    datapath('questions-words.txt'))\n",
    "eval_wordsim_text8_augmented_300 = model_augmented_300.wv.evaluate_word_pairs(\n",
    "    datapath('wordsim353.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wordsim353:\n",
      "Google News:  PearsonRResult(statistic=0.6238773487289394, pvalue=1.7963224351224885e-39)\n",
      "Text8:  PearsonRResult(statistic=0.6191131746160552, pvalue=1.6004556742509145e-38)\n",
      "Text8 Augmented:  PearsonRResult(statistic=0.4970035845305565, pvalue=2.019254963728344e-23)\n",
      "Text8 Augmented 300:  PearsonRResult(statistic=0.5106467378462217, pvalue=7.749511810213081e-25)\n",
      "\n",
      "Questions Words:\n",
      "Google News:\t\t 0.7401448525607863\n",
      "Text8:\t\t\t 0.23621473046502497\n",
      "Text8 Augmented:\t 0.2873069393082445\n",
      "Text8 Augmented 300:\t 0.3540896236676093\n"
     ]
    }
   ],
   "source": [
    "print(\"Wordsim353:\")\n",
    "print(\"Google News: \", eval_wordsim[0])\n",
    "print(\"Text8: \", eval_wordsim_text8[0])\n",
    "print(\"Text8 Augmented: \", eval_wordsim_text8_augmented[0])\n",
    "print(\"Text8 Augmented 300: \", eval_wordsim_text8_augmented_300[0])\n",
    "\n",
    "print(\"\\nQuestions Words:\")\n",
    "print(\"Google News:\\t\\t\", eval_qwords[0])\n",
    "print(\"Text8:\\t\\t\\t\", eval_qwords_text8[0])\n",
    "print(\"Text8 Augmented:\\t\", eval_qwords_text8_augmented[0])\n",
    "print(\"Text8 Augmented 300:\\t\", eval_qwords_text8_augmented_300[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tokens dans le modèle Google News (dimension de 300):\t\t 3000000\n",
      "Nombre de tokens dans le modèle Text8 (dimension de 100):\t\t 71290\n",
      "Nombre de tokens dans le modèle Text8 Augmented (dimension de 100):\t 124372\n"
     ]
    }
   ],
   "source": [
    "model_augmented_tokens, model_augmented_dim = model_augmented.wv.vectors.shape\n",
    "\n",
    "print(\n",
    "    f'Nombre de tokens dans le modèle Google News (dimension de {w2v_vec_dim}):\\t\\t {w2v_vec_tokens}')\n",
    "print(\n",
    "    f'Nombre de tokens dans le modèle Text8 (dimension de {model_100_dim}):\\t\\t {model_100_tokens}')\n",
    "print(\n",
    "    f'Nombre de tokens dans le modèle Text8 Augmented (dimension de {model_augmented_dim}):\\t {model_augmented_tokens}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les modèles augmentés sont meilleurs sur `Questions Words` que le modèle Text8 de base, mais toujours beaucoup moins bons que le modèle Google News. On observe que le nombre de tokens dans le modèle augmenté a presque doublé par rapport au modèle Text8 de base, il semble que la taille du corpus puis du vocabulaire soient donc des facteurs influençant la performance du modèle. Le score de similarité sur `Wordsim353` est par contre moins bon que celui du modèle Text8 de base et possède une pvalue plus élevée, indiquant une corrélation moins forte. On suppose que le mélange de deux corpus différents peut avoir un impact négatif sur la corrélation.\n",
    "\n",
    "Nous avons également entrainé un modèle avec une dimension de 300 pour ses embeddings pour se rapprocher des paramètres du modèle Google News. Cela a également permis d'augmenter la performance du modèle sur `Questions Words` et a légèrement mitigé la perte de performances sur `Wordsim353`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
