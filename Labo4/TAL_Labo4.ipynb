{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tester et évaluer un modèle entraîné sur Google News\n",
    "a. Installez gensim, une librairie Python qui fournit des outils pour travailler avec Word2Vec (avec conda ou avec pip). Prenez la version 3.8.3, et non pas la nouvelle version 4.0.X. \n",
    "\n",
    "Obtenez depuis gensim le modèle word2vec pré-entraîné sur le corpus Google News en écrivant : w2v_model = gensim.downloader.load(\"word2vec-google-news-300\"), ce qui téléchargera le fichier la première fois. Ne gardez en mémoire que les vecteurs des mots, en écrivant : « w2v_vectors = w2v_model.wv » puis « del w2v_model ».\n",
    "\n",
    "• Une fois que vous avez téléchargé le modèle, vous pouvez utiliser votre copie locale : w2v_vectors = KeyedVectors.load_word2vec_format(path_to_file, binary=True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models, downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_model = downloader.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "path_to_file = '~/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz'\n",
    "w2v_vectors = KeyedVectors.load_word2vec_format(path_to_file, binary=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Quelle place mémoire occupe le processus du notebook une fois les vecteurs de mots chargés ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environ 4GB de RAM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Quelle est la dimension de l’espace vectoriel dans lequel les mots sont représentés ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(w2v_vectors.vector_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Quelle est la taille du vocabulaire du modèle ? Affichez cinq mots (anglais) qui sont dans le vocabulaire et deux qui ne le sont pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000000, 300)\n"
     ]
    }
   ],
   "source": [
    "print(w2v_vectors.vectors.shape)\n",
    "\n",
    "# La taille du vocabulaire est de 3'000'000 de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is cat in the vocabulary? True\n",
      "Is bob in the vocabulary? True\n",
      "Is knife in the vocabulary? True\n",
      "Is sea in the vocabulary? True\n",
      "Is lol in the vocabulary? True\n",
      "Is yolo in the vocabulary? False\n",
      "Is cuck in the vocabulary? False\n"
     ]
    }
   ],
   "source": [
    "words = ['cat', 'bob', 'knife', 'sea', 'lol', 'yolo', 'cuck']\n",
    "\n",
    "for word in words:\n",
    "    print(f\"Is {word} in the vocabulary? {w2v_vectors.has_index_for(word)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Quelle est la distance entre les mots rabbit et carrot ? Veuillez aussi expliquer en une phrase comment on mesurer les distances entre deux mots dans cet espace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6369357705116272"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vectors.distance('rabbit', 'carrot')\n",
    "\n",
    "# La distance entre deux mots est mesurée en utilisant la similarité cosinus. En effet, la distance correspond à 1 - la similarité."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Considérez au moins 5 paires de mots, certains proches par leurs sens, d’autres plus éloignés. Pour chaque paire, calculez la distance entre les deux mots. Veuillez indiquer si les distances obtenues correspondent à vos intuitions sur la proximité des sens des mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between festival and watch : 0.9337479248642921\n",
      "Distance between confident and cocky : 0.6400514543056488\n",
      "Distance between tree and leaf : 0.517714649438858\n",
      "Distance between meticulous and nitpicky : 0.704185277223587\n",
      "Distance between dog and car : 0.6899985373020172\n"
     ]
    }
   ],
   "source": [
    "word_pairs = [('festival', 'watch'), ('confident', 'cocky'), ('tree', 'leaf'), ('meticulous', 'nitpicky'), ('dog', 'car')]\n",
    "for pair in word_pairs:\n",
    "    print(f'Distance between {pair[0]} and {pair[1]} : {w2v_vectors.distance(pair[0], pair[1])}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certaines paires obtiennent des distances qui correspondent à nos intuitions, d'autres non. Par exemple, les paires (festival, watch) et (dog, car) ont une distance élevée car les mots n'ont pas de sens proche. \n",
    "\n",
    "Par contre, d'autres paires comme (tree, leaf), (confident, cocky) ou (meticulous, nitpicky) ont une distance plus élevée que ce que nous aurions pensé."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Pouvez-vous trouver des mots de sens opposés mais qui sont proches dans l’espace vectoriel ? Comment expliquez vous cela ? Est-ce une qualité ou un défaut du modèle word2vec ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance entre good et bad : 0.2809947729110718\n",
      "Distance entre up et down : 0.36030077934265137\n",
      "Distance entre black et white : 0.1907784342765808\n"
     ]
    }
   ],
   "source": [
    "opposite_pairs = [('good', 'bad'), ('up', 'down'), ('black', 'white')]\n",
    "\n",
    "for pair in opposite_pairs:\n",
    "    print(f'Distance entre {pair[0]} et {pair[1]} : {w2v_vectors.distance(pair[0], pair[1])}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela est dû au fait que les mots peuvent être utilisés dans le même contexte et possèdent un lien sémantique. Il s'agit d'une qualité du modèle car il arrive alors à faire des rapprochements plus subtiles que simplement trouver des similarités entre synonymes par exemple."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. En vous aidant de la documentation de Gensim sur KeyedVectors, calculez le score du modèle word2vec sur les données WordSimilarity-353. (La doc vous permettra aussi de récupérer le fichier.) Expliquez en 1-2 phrases comment ce score est calculé et ce qu’il mesure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. En vous aidant de la documentation, calculez le score du modèle word2vec sur les données questions-words.txt. Attention, cette évaluation prend une dizaine de minutes. Expliquez en 1-2 phrases comment ce score est calculé et ce qu'il mesure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
